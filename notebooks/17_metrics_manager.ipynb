{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40248bea-f486-4dec-a7dc-5ed932ce1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "748848b2-5491-452f-8263-cd9294105393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 17:06:53.896968: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-09 17:06:53.932655: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-09 17:06:53.941981: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-09 17:06:54.010795: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-09 17:06:55.576328: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Any\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ab2850-ab07-4e8f-973f-b9a1d0698e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5f84b1-5df3-4fa0-8ea6-20113b86f668",
   "metadata": {},
   "source": [
    "## Implementing the helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d98cfe99-e141-4fc1-ac22-0d1b15ac8d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_iou_xyxy(box: np.ndarray, boxes: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute IoU between a single box and an array of boxes.\n",
    "    \n",
    "    Args:\n",
    "        box:   shape (4,)  [x1, y1, x2, y2]\n",
    "        boxes: shape (N,4) [x1, y1, x2, y2] for each box\n",
    "\n",
    "    Returns:\n",
    "        ious: shape (N,) IoU between `box` and each of `boxes`\n",
    "    \"\"\"\n",
    "    box = np.asarray(box, dtype=np.float32)\n",
    "    boxes = np.asarray(boxes, dtype=np.float32)\n",
    "\n",
    "    if boxes.size == 0:\n",
    "        return np.zeros((0,), dtype=np.float32)\n",
    "\n",
    "    # Intersection coords\n",
    "    x1 = np.maximum(box[0], boxes[:, 0])\n",
    "    y1 = np.maximum(box[1], boxes[:, 1])\n",
    "    x2 = np.minimum(box[2], boxes[:, 2])\n",
    "    y2 = np.minimum(box[3], boxes[:, 3])\n",
    "\n",
    "    inter_w = np.maximum(0.0, x2 - x1)\n",
    "    inter_h = np.maximum(0.0, y2 - y1)\n",
    "    inter = inter_w * inter_h\n",
    "\n",
    "    # Areas\n",
    "    area_box = (box[2] - box[0]) * (box[3] - box[1])\n",
    "    area_boxes = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "\n",
    "    # Union\n",
    "    union = area_box + area_boxes - inter\n",
    "    union = np.maximum(union, 1e-6)  # avoid division by zero\n",
    "\n",
    "    return inter / union\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48177e5d-8b4c-49e4-bc7a-ab603c3fb83f",
   "metadata": {},
   "source": [
    "## Implementing the Base Class For Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5889b575-d208-42ed-b418-6a88983a2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseMetric(ABC):\n",
    "    def __init__(self, name:str):\n",
    "        self._name = name\n",
    "        \n",
    "    @abstractmethod\n",
    "    def update(self,preds: list[Dict[str,Any]], ground_truth: list[Dict[str,Any]]):\n",
    "        pass\n",
    "        \n",
    "    @abstractmethod\n",
    "    def compute(self):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "        \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341d0de8-efcc-4aae-8624-54ac2397b8f0",
   "metadata": {},
   "source": [
    "## Implmenting the Derived Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b64a1512-f44e-4c1f-9f66-dac58dab84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOCMAP(BaseMetric):\n",
    "    def __init__(self, iou_thresh,num_classes: int,name: str):\n",
    "        super().__init__(name = name)\n",
    "        \n",
    "        if isinstance(iou_thresh, (list, tuple)):\n",
    "            self.iou_thresh = [float(t) for t in iou_thresh]\n",
    "        else:\n",
    "            self.iou_thresh = [float(iou_thresh)]\n",
    "            \n",
    "        self.num_classes = num_classes\n",
    "        # Initialize the pred & gt lists\n",
    "        self._preds = []\n",
    "        self._ground_truth = []\n",
    "\n",
    "    def reset(self):\n",
    "        self._preds = []\n",
    "        self._ground_truth = []\n",
    "\n",
    "    def update(self,preds,ground_truth):\n",
    "        for pred in preds:\n",
    "            self._preds.append(\n",
    "                (pred['image_id'], pred['boxes'], pred['scores'], pred['labels'])\n",
    "            )\n",
    "\n",
    "        for gt in ground_truth:\n",
    "            self._ground_truth.append(\n",
    "                (gt['image_id'], gt['boxes'], gt['labels'])\n",
    "            )\n",
    "\n",
    "    def compute(self):\n",
    "        if len(self._ground_truth) == 0:\n",
    "            results = {}\n",
    "            for t in self.iou_thresh:\n",
    "                results[f\"mAP@{t}\"] = 0.0\n",
    "            return results\n",
    "\n",
    "        combined = {}\n",
    "        for t in self.iou_thresh:\n",
    "            stats_t = self._compute_for_single_iou(t)\n",
    "            combined.update(stats_t)\n",
    "\n",
    "        return combined\n",
    "\n",
    "    def _compute_for_single_iou(self, iou_thr):\n",
    "    \n",
    "        # GT Structures per class\n",
    "        ground_truth_per_class = {c: {} for c in range(self.num_classes)}\n",
    "        num_pos_per_class = {c: 0 for c in range(self.num_classes)}\n",
    "\n",
    "        for image_id, gt_boxes, gt_labels in self._ground_truth:\n",
    "            # Copying the boxes for calculations\n",
    "            gt_boxes = np.asarray(gt_boxes,dtype = np.float32)\n",
    "            gt_labels = np.asarray(gt_labels,dtype = np.int32)\n",
    "\n",
    "            # Iterating over the boxes and their corresponding labels\n",
    "            for gt_box, gt_label in zip(gt_boxes, gt_labels):\n",
    "                class_num = int(gt_label)\n",
    "                if class_num == 0:\n",
    "                    # Background which is not needed\n",
    "                    continue\n",
    "\n",
    "                if image_id not in ground_truth_per_class[class_num]:\n",
    "                    # Initial creation of the images records\n",
    "                    ground_truth_per_class[class_num][image_id] = {\n",
    "                        \"boxes\": [],\n",
    "                        \"detected\": []\n",
    "                    }\n",
    "\n",
    "                ground_truth_per_class[class_num][image_id][\"boxes\"].append(gt_box)\n",
    "                ground_truth_per_class[class_num][image_id][\"detected\"].append(False)\n",
    "                num_pos_per_class[class_num] = num_pos_per_class[class_num] + 1\n",
    "\n",
    "        # Making them into numpy arrays for easier reduction\n",
    "        for class_num in range(self.num_classes):\n",
    "            for image_id, data in ground_truth_per_class[class_num].items():\n",
    "                data['boxes'] = np.asarray(data['boxes'], dtype=np.float32)\n",
    "                data['detected'] = np.asarray(data[\"detected\"], dtype=bool)\n",
    "\n",
    "        # Calculating the predictions per class\n",
    "        pred_per_class = {c: [] for c in range(self.num_classes)}\n",
    "\n",
    "        for image_id, pred_box, pred_scores, pred_labels in self._preds:\n",
    "            pred_box = np.asarray(pred_box,dtype = np.float32)\n",
    "            pred_scores = np.asarray(pred_scores,dtype = np.float32)\n",
    "            pred_labels = np.asarray(pred_labels,dtype = np.int32)\n",
    "\n",
    "            # Iterating through all the predictions\n",
    "            for bbox, score, label in zip(pred_box, pred_scores, pred_labels):\n",
    "                class_num = int(label)\n",
    "                if class_num == 0:\n",
    "                    # Background which is not needed\n",
    "                    continue\n",
    "\n",
    "                pred_per_class[class_num].append({\"image_id\": image_id, \"box\": bbox, \"score\": float(score)})\n",
    "\n",
    "\n",
    "        # Now calculating AP per class after creation of the data\n",
    "        ap_per_class = {}\n",
    "\n",
    "        for class_num in range(1, self.num_classes):\n",
    "            preds_for_class = pred_per_class[class_num]\n",
    "            num_pos = num_pos_per_class[class_num]\n",
    "\n",
    "            if num_pos == 0:\n",
    "                # There was no ground truth box for this class\n",
    "                continue\n",
    "\n",
    "            if len(preds_for_class) == 0:\n",
    "                ap_per_class[class_num] = 0.0\n",
    "                continue\n",
    "\n",
    "            # Sorting the predictions by score\n",
    "            preds_for_class.sort(key = lambda data: data['score'],reverse = True)\n",
    "\n",
    "            TP = np.zeros(len(preds_for_class), dtype = np.float32)\n",
    "            FP = np.zeros(len(preds_for_class), dtype = np.float32)\n",
    "\n",
    "            for index, pred in enumerate(preds_for_class):\n",
    "                image_id = pred['image_id']\n",
    "                bbox = np.asarray(pred['box'], dtype = np.float32)\n",
    "\n",
    "                if image_id not in ground_truth_per_class[class_num]:\n",
    "                    FP[index] = 1.0\n",
    "                    continue\n",
    "\n",
    "                ground_truth_data = ground_truth_per_class[class_num][image_id]\n",
    "                ground_truth_boxes = ground_truth_data['boxes']\n",
    "                detected = ground_truth_data['detected']\n",
    "\n",
    "                iou_matrix = box_iou_xyxy(bbox, ground_truth_boxes)\n",
    "                max_iou_per_index = int(np.argmax(iou_matrix)) if iou_matrix.size > 0 else -1\n",
    "                max_iou = iou_matrix[max_iou_per_index] if iou_matrix.size > 0 else 0.0\n",
    "\n",
    "                if max_iou >= iou_thr and not detected[max_iou_per_index]:\n",
    "                    TP[index] = 1.0\n",
    "                    detected[max_iou_per_index] = True\n",
    "                else:\n",
    "                    FP[index] = 1.0\n",
    "\n",
    "            TP_cum = np.cumsum(TP)\n",
    "            FP_cum = np.cumsum(FP)\n",
    "\n",
    "            # Calculating the recall and precision\n",
    "            recall = TP_cum / float(num_pos)\n",
    "            precision = TP_cum / np.maximum(TP_cum + FP_cum, 1e-6) # division by zero safe guard\n",
    "\n",
    "            # calculate the AP\n",
    "            ap = self._voc_ap(recall,precision)\n",
    "            ap_per_class[class_num] = float(ap)\n",
    "\n",
    "        valid_aps = [ap for c, ap in ap_per_class.items() if num_pos_per_class[c] > 0]\n",
    "\n",
    "        if len(valid_aps) == 0.0:\n",
    "            mAP = 0.0\n",
    "        else:\n",
    "            mAP = float(np.mean(valid_aps))\n",
    "\n",
    "        results = {\n",
    "            f\"mAP@{iou_thr}\": mAP,\n",
    "        }\n",
    "\n",
    "        for c, ap in ap_per_class.items():\n",
    "            if num_pos_per_class[c] > 0:\n",
    "                results[f\"mAP@{iou_thr}/class_{c}\"] = ap\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _voc_ap(self, recall: np.ndarray, precision: np.ndarray):\n",
    "        mrec = np.concatenate(([0.0], recall, [1.0]))\n",
    "        mpre = np.concatenate(([0.0], precision, [0.0]))\n",
    "\n",
    "        for i in range(mpre.size - 1, 0, -1):\n",
    "            mpre[i - 1] = max(mpre[i - 1], mpre[i])\n",
    "\n",
    "        idx = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "        ap = 0.0\n",
    "        for i in idx:\n",
    "            ap += (mrec[i + 1] - mrec[i]) * mpre[i + 1]\n",
    "\n",
    "        return ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "356c74ef-638d-4cef-9e46-6496a2ea2d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCOMAP(BaseMetric):\n",
    "    def __init__(self, iou_thresh: list[float] | None,num_classes: int,name: str):\n",
    "        super().__init__(name = name)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        if iou_thresh is None:\n",
    "            iou_thresh = [0.5 + 0.05 * i for i in range(10)]\n",
    "\n",
    "        if isinstance(iou_thresh, (list, tuple)):\n",
    "            self.iou_thresh = [float(t) for t in iou_thresh]\n",
    "        else:\n",
    "            self.iou_thresh = [float(iou_thresh)]\n",
    "        \n",
    "        # Initialize the pred & gt lists\n",
    "        self._preds = []\n",
    "        self._ground_truth = []\n",
    "\n",
    "    def reset(self):\n",
    "        self._preds = []\n",
    "        self._ground_truth = []\n",
    "\n",
    "    def update(self,preds,ground_truth):\n",
    "        for pred in preds:\n",
    "            self._preds.append(\n",
    "                (pred['image_id'], pred['boxes'], pred['scores'], pred['labels'])\n",
    "            )\n",
    "\n",
    "        for gt in ground_truth:\n",
    "            self._ground_truth.append(\n",
    "                (gt['image_id'], gt['boxes'], gt['labels'])\n",
    "            )\n",
    "\n",
    "    def compute(self):\n",
    "        if len(self._ground_truth) == 0:\n",
    "            # No GT at all: define all metrics as 0\n",
    "            key = f\"{self.name}/mAP@[{self.iou_thresh[0]:.2f}:{self.iou_thresh[-1]:.2f}]\"\n",
    "            return {key: 0.0}\n",
    "\n",
    "        num_iou = len(self.iou_thresh)\n",
    "\n",
    "        # GT Structures per class\n",
    "        ground_truth_per_class = {c: {} for c in range(self.num_classes)}\n",
    "        num_pos_per_class = {c: 0 for c in range(self.num_classes)}\n",
    "\n",
    "        for image_id, gt_boxes, gt_labels in self._ground_truth:\n",
    "            # Copying the boxes for calculations\n",
    "            gt_boxes = np.asarray(gt_boxes,dtype = np.float32)\n",
    "            gt_labels = np.asarray(gt_labels,dtype = np.int32)\n",
    "\n",
    "            # Iterating over the boxes and their corresponding labels\n",
    "            for gt_box, gt_label in zip(gt_boxes, gt_labels):\n",
    "                class_num = int(gt_label)\n",
    "                if class_num == 0:\n",
    "                    # Background which is not needed\n",
    "                    continue\n",
    "\n",
    "                if image_id not in ground_truth_per_class[class_num]:\n",
    "                    # Initial creation of the images records\n",
    "                    ground_truth_per_class[class_num][image_id] = {\n",
    "                        \"boxes\": [],\n",
    "                    }\n",
    "\n",
    "                ground_truth_per_class[class_num][image_id][\"boxes\"].append(gt_box)\n",
    "                num_pos_per_class[class_num] = num_pos_per_class[class_num] + 1\n",
    "\n",
    "        for class_num in range(self.num_classes):\n",
    "            for image_id, data in ground_truth_per_class[class_num].items():\n",
    "                data['boxes'] = np.asarray(data['boxes'], dtype=np.float32)\n",
    "                \n",
    "        # Calculating the predictions per class\n",
    "        pred_per_class = {c: [] for c in range(self.num_classes)}\n",
    "\n",
    "        for image_id, pred_box, pred_scores, pred_labels in self._preds:\n",
    "            pred_box = np.asarray(pred_box,dtype = np.float32)\n",
    "            pred_scores = np.asarray(pred_scores,dtype = np.float32)\n",
    "            pred_labels = np.asarray(pred_labels,dtype = np.int32)\n",
    "\n",
    "            # Iterating through all the predictions\n",
    "            for bbox, score, label in zip(pred_box, pred_scores, pred_labels):\n",
    "                class_num = int(label)\n",
    "                if class_num == 0:\n",
    "                    # Background which is not needed\n",
    "                    continue\n",
    "\n",
    "                pred_per_class[class_num].append({\"image_id\": image_id, \"box\": bbox, \"score\": float(score)})\n",
    "\n",
    "        AP = np.full((self.num_classes, num_iou), np.nan, dtype=np.float32)\n",
    "\n",
    "        for class_num in range(1, self.num_classes):\n",
    "            preds_for_class = pred_per_class[class_num]\n",
    "            num_pos = num_pos_per_class[class_num]\n",
    "\n",
    "            if num_pos == 0:\n",
    "                # There was no ground truth box for this class\n",
    "                continue\n",
    "\n",
    "            if len(preds_for_class) == 0:\n",
    "                ap_per_class[class_num] = 0.0\n",
    "                continue\n",
    "\n",
    "            # Sorting the predictions by score\n",
    "            preds_for_class.sort(key = lambda data: data['score'],reverse = True)\n",
    "\n",
    "            for index, iou_thr in enumerate(self.iou_thresh):\n",
    "                detected_flags = {}\n",
    "                \n",
    "                for image_id, data in ground_truth_per_class[class_num].items():\n",
    "                    num_gt = data[\"boxes\"].shape[0]\n",
    "                    detected_flags[image_id] = np.zeros(num_gt, dtype=bool)\n",
    "\n",
    "                TP = np.zeros(len(preds_for_class), dtype = np.float32)\n",
    "                FP = np.zeros(len(preds_for_class), dtype = np.float32)\n",
    "\n",
    "                for pred_index, pred in enumerate(preds_for_class):\n",
    "                    image_id = pred['image_id']\n",
    "                    bbox = np.asarray(pred['box'], dtype = np.float32)\n",
    "\n",
    "                    if image_id not in ground_truth_per_class[class_num]:\n",
    "                        FP[pred_index] = 1.0\n",
    "                        continue\n",
    "\n",
    "                    ground_truth_data = ground_truth_per_class[class_num][image_id]\n",
    "                    ground_truth_boxes = ground_truth_data['boxes']\n",
    "                    det_flags = detected_flags[image_id]\n",
    "\n",
    "                    iou_matrix = box_iou_xyxy(bbox, ground_truth_boxes)\n",
    "                    if iou_matrix.size == 0:\n",
    "                        FP[pred_index] = 1.0\n",
    "                        continue\n",
    "\n",
    "                    max_iou_index = int(np.argmax(iou_matrix))\n",
    "                    max_iou = float(iou_matrix[max_iou_index])\n",
    "\n",
    "                    if max_iou >= iou_thr and not det_flags[max_iou_index]:\n",
    "                        TP[pred_index] = 1.0\n",
    "                        det_flags[max_iou_index] = True\n",
    "                    else:\n",
    "                        FP[pred_index] = 1.0\n",
    "\n",
    "                TP_cum = np.cumsum(TP)\n",
    "                FP_cum = np.cumsum(FP)\n",
    "\n",
    "                recall = TP_cum / float(num_pos)\n",
    "                precision = TP_cum / np.maximum(TP_cum + FP_cum, 1e-6) # division by zero safe guard\n",
    "\n",
    "                AP[class_num,index] = self._coco_ap_101(recall, precision)\n",
    "                \n",
    "        valid_classes  = [c for c in range(1, self.num_classes) if num_pos_per_class[c] > 0]\n",
    "\n",
    "        if len(valid_classes) == 0:\n",
    "            mAP = 0.0\n",
    "            ap50 = 0.0\n",
    "            ap75 = 0.0\n",
    "        else:\n",
    "            AP_valid = AP[valid_classes, :]\n",
    "            mAP = float(np.nanmean(AP_valid))\n",
    "            \n",
    "            ap50 = None\n",
    "            ap75 = None\n",
    "\n",
    "            if 0.5 in self.iou_thresh:\n",
    "                t50_idx = self.iou_thresh.index(0.5)\n",
    "                ap50 = float(np.nanmean(AP_valid[:, t50_idx]))\n",
    "            if 0.75 in self.iou_thresh:\n",
    "                t75_idx = self.iou_thresh.index(0.75)\n",
    "                ap75 = float(np.nanmean(AP_valid[:, t75_idx]))\n",
    "\n",
    "        key_main = f\"{self.name}/mAP@[{self.iou_thresh[0]:.2f}:{self.iou_thresh[-1]:.2f}]\"\n",
    "        results: dict[str, float] = {key_main: mAP}\n",
    "\n",
    "        if ap50 is not None:\n",
    "            results[f\"{self.name}/AP@0.50\"] = ap50\n",
    "        if ap75 is not None:\n",
    "            results[f\"{self.name}/AP@0.75\"] = ap75\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _coco_ap_101(self, recall: np.ndarray, precision: np.ndarray):\n",
    "        \n",
    "        if recall.size == 0:\n",
    "            return 0.0\n",
    "\n",
    "        rec = np.asarray(recall, dtype=np.float32)\n",
    "        prec = np.asarray(precision, dtype=np.float32)\n",
    "\n",
    "        recall_samples = np.linspace(0.0, 1.0, 101, dtype=np.float32)\n",
    "        precisions_interp = np.zeros_like(recall_samples)\n",
    "\n",
    "        for i, r in enumerate(recall_samples):\n",
    "            # precision at recall >= r\n",
    "            mask = rec >= r\n",
    "            if np.any(mask):\n",
    "                precisions_interp[i] = np.max(prec[mask])\n",
    "            else:\n",
    "                precisions_interp[i] = 0.0\n",
    "\n",
    "        return float(np.mean(precisions_interp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6303ba49-7616-4512-beef-a33667a31976",
   "metadata": {},
   "source": [
    "## Implemented The Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b21cec9-60f8-4518-bf91-7a01104bed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsManager:\n",
    "    def __init__(self, metrics:list[BaseMetric], prefix: str | None = None):\n",
    "        self.metrics = metrics\n",
    "        self.prefix = prefix or \"\"\n",
    "\n",
    "    def update(self, pred: dict[str,Any], ground_truth: dict[str,Any]):\n",
    "        for metric in self.metrics:\n",
    "            metric.update(pred,ground_truth)\n",
    "\n",
    "    def compute(self):\n",
    "        combined: dict[str,float] = {}\n",
    "        for metric in self.metrics:\n",
    "            stat = metric.compute()\n",
    "            for key,value in stat.items():\n",
    "                k = f\"{self.prefix}{metric.name}/{key}\"\n",
    "                combined[k] = value\n",
    "        return combined\n",
    "        \n",
    "    def reset(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2369beb6-c7d6-4c36-946b-f820ea767164",
   "metadata": {},
   "source": [
    "# Implemented Factory Pattern Using Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aacd97dd-1663-4e7d-9c53-34c18ca9c6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_metrics_config(config: dict):\n",
    "\n",
    "    eval_cfg = config[\"eval\"]\n",
    "    metric_cfg = eval_cfg[\"metrics\"]\n",
    "    num_classes = config[\"model\"][\"num_classes\"]\n",
    "    \n",
    "    metrics: list[BaseMetric] = []\n",
    "\n",
    "    for metric_name, mc in metric_cfg.items():\n",
    "        metric_type = mc.get(\"type\", \"voc_ap\")\n",
    "        if metric_type == \"voc_ap\":\n",
    "            metrics.append(\n",
    "                VOCMAP(\n",
    "                    iou_thresh=mc.get(\"iou_thresholds\", [0.5]),\n",
    "                    num_classes=num_classes,\n",
    "                    name=metric_name,  # use key from YAML\n",
    "                )\n",
    "            )\n",
    "\n",
    "        elif metric_type == \"coco_map\":\n",
    "            metrics.append(\n",
    "                COCOMAP(\n",
    "                    iou_thresh=mc.get(\"iou_thresholds\",\n",
    "                                          [0.5, 0.55, 0.6, 0.65,\n",
    "                                           0.7, 0.75, 0.8, 0.85,\n",
    "                                           0.9, 0.95]),\n",
    "                    num_classes=num_classes,\n",
    "                    name=metric_name,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric type: {metric_type!r} for {metric_name!r}\")\n",
    "\n",
    "    return MetricsManager(metrics=metrics, prefix=f\"{eval_cfg['dataset_split']}/\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99d4e379-da92-4a2f-a3d6-214aa1c93d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilenetv2ssd.core.config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95dee5de-caa8-46a2-be6f-d794d1940cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cfg_path = \"configs/train/default.yaml\"\n",
    "model_cfg_path = \"configs/model/mobilenetv2_ssd_voc.yaml\"\n",
    "data_cfg_path = \"configs/data/voc_224.yaml\"\n",
    "eval_cfg_path = \"configs/eval/default.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751869a-01c5-4477-9cea-f2dbb41fa3e8",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbde0dab-bf84-4a4c-a2ee-51990e2399ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(main_cfg_path,model_cfg_path,data_cfg_path,eval_cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5784f971-346d-4183-9160-3fd13b2dea1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_split': 'val',\n",
       " 'nms': {'iou_threshold': 0.5,\n",
       "  'score_threshold': 0.05,\n",
       "  'max_detections_per_image': 100,\n",
       "  'max_detections_per_class': 50},\n",
       " 'metrics': {'voc_ap_50': {'type': 'voc_ap',\n",
       "   'iou_thresholds': [0.5, 0.75],\n",
       "   'use_07_metric': False},\n",
       "  'coco_map': {'type': 'coco_map',\n",
       "   'iou_thresholds': [0.5, 0.75],\n",
       "   'use_07_metric': False}},\n",
       " 'visualization': {'enabled': False,\n",
       "  'max_images': 16,\n",
       "  'output_dir': '/mnt/d/dev/MobileNetV2-SSD/eval_vis'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['eval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5ef4c53-ece0-4af1-b9d7-b63c22b86963",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_manager = build_metrics_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7f9f02a-e1e0-4168-aaca-3bf2f71da1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val/voc_ap_50/mAP@0.5': 0.0,\n",
       " 'val/voc_ap_50/mAP@0.75': 0.0,\n",
       " 'val/coco_map/coco_map/mAP@[0.50:0.75]': 0.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_manager.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a03116b-d8f1-48f9-9d6d-61ccd7a75603",
   "metadata": {},
   "outputs": [],
   "source": [
    "gts = [\n",
    "    {\n",
    "        \"image_id\": \"img1\",\n",
    "        \"boxes\":  [[0.0, 0.0, 100.0, 100.0]],  # one GT box\n",
    "        \"labels\": [1],\n",
    "    }\n",
    "]\n",
    "\n",
    "# One prediction exactly on top of GT\n",
    "preds = [\n",
    "    {\n",
    "        \"image_id\": \"img1\",\n",
    "        \"boxes\":  [[0.0, 0.0, 100.0, 100.0]],  # same as GT\n",
    "        \"scores\": [0.9],\n",
    "        \"labels\": [1],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87354688-6432-4253-a10f-bc069a80bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_manager.update(preds,gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5d96044-d51a-463f-b446-7c96f7fc1658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val/voc_ap_50/mAP@0.5': 1.0,\n",
       " 'val/voc_ap_50/mAP@0.5/class_1': 1.0,\n",
       " 'val/voc_ap_50/mAP@0.75': 1.0,\n",
       " 'val/voc_ap_50/mAP@0.75/class_1': 1.0,\n",
       " 'val/coco_map/coco_map/mAP@[0.50:0.75]': 1.0,\n",
       " 'val/coco_map/coco_map/AP@0.50': 1.0,\n",
       " 'val/coco_map/coco_map/AP@0.75': 1.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_manager.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f291239-f57f-48a8-bcc9-fc255262dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gts = [\n",
    "    {\n",
    "        \"image_id\": \"img1\",\n",
    "        \"boxes\":  [[0.0, 0.0, 100.0, 100.0]],\n",
    "        \"labels\": [1],\n",
    "    }\n",
    "]\n",
    "\n",
    "preds = [\n",
    "    {\n",
    "        \"image_id\": \"img1\",\n",
    "        \"boxes\": [\n",
    "            [200.0, 200.0, 300.0, 300.0],  # FP: no overlap with GT\n",
    "            [0.0,   0.0,   100.0, 100.0],  # TP: exact match\n",
    "        ],\n",
    "        \"scores\": [0.9, 0.8],  # FP ranked above TP\n",
    "        \"labels\": [1, 1],\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d3186c7-8ea5-4950-ac9c-a0f6a1caf25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val/voc_ap_50/mAP@0.5': 0.5,\n",
       " 'val/voc_ap_50/mAP@0.5/class_1': 0.5,\n",
       " 'val/voc_ap_50/mAP@0.75': 0.5,\n",
       " 'val/voc_ap_50/mAP@0.75/class_1': 0.5,\n",
       " 'val/coco_map/coco_map/mAP@[0.50:0.75]': 0.5,\n",
       " 'val/coco_map/coco_map/AP@0.50': 0.5,\n",
       " 'val/coco_map/coco_map/AP@0.75': 0.5}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_manager = build_metrics_config(config)\n",
    "metrics_manager.update(preds,gts)\n",
    "metrics_manager.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b13d4986-9f70-4528-b32f-ae7f12d20bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gts = [\n",
    "    # img1: cat + dog\n",
    "    {\n",
    "        \"image_id\": \"img1\",\n",
    "        \"boxes\":  [\n",
    "            [0.0,   0.0,   100.0, 100.0],   # cat\n",
    "            [150.0, 150.0, 250.0, 250.0],   # dog\n",
    "        ],\n",
    "        \"labels\": [1, 2],\n",
    "    },\n",
    "    # img2: only dog\n",
    "    {\n",
    "        \"image_id\": \"img2\",\n",
    "        \"boxes\":  [\n",
    "            [50.0, 50.0, 150.0, 150.0],    # dog\n",
    "        ],\n",
    "        \"labels\": [2],\n",
    "    },\n",
    "]\n",
    "\n",
    "preds = [\n",
    "    # Predictions for img1\n",
    "    {\n",
    "        \"image_id\": \"img1\",\n",
    "        \"boxes\": [\n",
    "            [0.0,   0.0,   100.0, 100.0],   # good cat (TP)\n",
    "            [160.0, 160.0, 260.0, 260.0],   # decent dog (TP, IoU > 0.5-ish)\n",
    "            [300.0, 300.0, 400.0, 400.0],   # random FP (no GT)\n",
    "        ],\n",
    "        \"scores\": [0.9, 0.8, 0.3],\n",
    "        \"labels\": [1,   2,   1],           # last box wrongly predicted as cat\n",
    "    },\n",
    "    # Predictions for img2\n",
    "    {\n",
    "        \"image_id\": \"img2\",\n",
    "        \"boxes\": [\n",
    "            [60.0, 60.0, 140.0, 140.0],     # decent dog (TP)\n",
    "        ],\n",
    "        \"scores\": [0.95],\n",
    "        \"labels\": [2],\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ae099e7-7eeb-435c-933a-efc94a389698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val/voc_ap_50/mAP@0.5': 1.0,\n",
       " 'val/voc_ap_50/mAP@0.5/class_1': 1.0,\n",
       " 'val/voc_ap_50/mAP@0.5/class_2': 1.0,\n",
       " 'val/voc_ap_50/mAP@0.75': 0.5,\n",
       " 'val/voc_ap_50/mAP@0.75/class_1': 1.0,\n",
       " 'val/voc_ap_50/mAP@0.75/class_2': 0.0,\n",
       " 'val/coco_map/coco_map/mAP@[0.50:0.75]': 0.75,\n",
       " 'val/coco_map/coco_map/AP@0.50': 1.0,\n",
       " 'val/coco_map/coco_map/AP@0.75': 0.5}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_manager = build_metrics_config(config)\n",
    "metrics_manager.update(preds,gts)\n",
    "metrics_manager.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7a78d6-d25f-421f-8948-e0edb455dc29",
   "metadata": {},
   "source": [
    "## Implemented The Adapter Pattern to Convert Prediction To Metric Input Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3b6706c-7ef2-4f38-99ab-00f8eb252ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_predictions_to_metric_format(nmsed_boxes, nmsed_scores, nmsed_classes, image_id, gt_boxes_xyxy, gt_labels, gt_valid_mask):\n",
    "    preds = []\n",
    "    gt = []\n",
    "\n",
    "    boxes = nmsed_boxes\n",
    "    scores = nmsed_scores\n",
    "    labels = nmsed_classes\n",
    "\n",
    "    gt_boxes = gt_boxes_xyxy\n",
    "    gt_labels = gt_labels\n",
    "    gt_masks = gt_valid_mask\n",
    "\n",
    "    image_ids = image_id\n",
    "\n",
    "    B = tf.shape(boxes)[0]\n",
    "\n",
    "    for i in range(B):\n",
    "        img_id = image_ids[i]\n",
    "\n",
    "        # Prediction boxes\n",
    "        pred_box = boxes[i]\n",
    "        pred_scores = scores[i]\n",
    "        pred_labels = labels[i]\n",
    "\n",
    "        preds.append({\"image_id\": img_id.numpy(),\"boxes\":   pred_box.numpy(), \"scores\":  pred_scores.numpy(),\"labels\":  pred_labels.numpy()})\n",
    "\n",
    "        # Ground truth box\n",
    "        gt_box = gt_boxes[i]\n",
    "        gt_label = gt_labels[i]\n",
    "        gt_mask = gt_masks[i]\n",
    "\n",
    "        gt_box = tf.boolean_mask(gt_box,gt_mask)\n",
    "        gt_label = tf.boolean_mask(gt_labels,gt_mask)\n",
    "\n",
    "        gt.append({\"image_id\": img_id.numpy(), \"boxes\":   gt_box.numpy(), \"labels\":  gt_label.numpy()})\n",
    "\n",
    "\n",
    "    return preds, gt\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4960c44c-7432-4c82-9115-e4bfe1aaa34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765318017.918077   33985 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1765318018.004198   33985 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1765318018.004260   33985 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1765318018.006057   33985 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1765318018.006142   33985 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1765318018.006178   33985 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1765318018.190348   33985 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1765318018.190432   33985 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-09 17:06:58.190444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-12-09 17:06:58.190468: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:198] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1765318018.192681   33985 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-09 17:06:58.192720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# NOTE: PREDS ARE IN XY COORDINATES\n",
    "boxes = tf.constant([\n",
    "        # image 0: one det\n",
    "        [[10.0, 10.0, 50.0, 50.0],    # det0\n",
    "         [0.0, 0.0, 0.0, 0.0]],       # padding\n",
    "        # image 1: one det\n",
    "        [[70.0, 70.0, 120.0, 120.0],  # det0 (far away from GT)\n",
    "         [0.0, 0.0, 0.0, 0.0]],       # padding\n",
    "    ], dtype=tf.float32)   \n",
    "\n",
    "scores = tf.constant([\n",
    "        [0.9, 0.0],   # image 0\n",
    "        [0.8, 0.0],   # image 1\n",
    "    ], dtype=tf.float32)\n",
    "\n",
    "labels = tf.constant([\n",
    "        [1, 0],       # image 0: first det is class 1, second padding\n",
    "        [1, 0],       # image 1: first det is class 1, second padding\n",
    "    ], dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccfd4094-4050-430a-9919-ba733e8a39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = tf.constant([\"101\", \"102\"], dtype=tf.string)\n",
    "\n",
    "gt_boxes = tf.constant([\n",
    "        # image 0: one GT box\n",
    "        [[10.0, 10.0, 50.0, 50.0],\n",
    "         [0.0, 0.0, 0.0, 0.0]],\n",
    "        # image 1: one GT box\n",
    "        [[10.0, 10.0, 50.0, 50.0],\n",
    "         [0.0, 0.0, 0.0, 0.0]],\n",
    "    ], dtype=tf.float32)\n",
    "\n",
    "gt_labels =  tf.constant([\n",
    "        [1, 0],   # image 0: one GT of class 1\n",
    "        [1, 0],   # image 1\n",
    "    ], dtype=tf.int32)\n",
    "\n",
    "gt_mask =  tf.constant([\n",
    "        [True, False],   # image 0: only first GT valid\n",
    "        [True, False],   # image 1\n",
    "    ], dtype=tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31dd9db0-9696-4ab5-b2d0-f953d592c1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'image_id': b'101',\n",
       "   'boxes': array([[10., 10., 50., 50.],\n",
       "          [ 0.,  0.,  0.,  0.]], dtype=float32),\n",
       "   'scores': array([0.9, 0. ], dtype=float32),\n",
       "   'labels': array([1, 0], dtype=int32)},\n",
       "  {'image_id': b'102',\n",
       "   'boxes': array([[ 70.,  70., 120., 120.],\n",
       "          [  0.,   0.,   0.,   0.]], dtype=float32),\n",
       "   'scores': array([0.8, 0. ], dtype=float32),\n",
       "   'labels': array([1, 0], dtype=int32)}],\n",
       " [{'image_id': b'101',\n",
       "   'boxes': array([[10., 10., 50., 50.]], dtype=float32),\n",
       "   'labels': array([[1, 0]], dtype=int32)},\n",
       "  {'image_id': b'102',\n",
       "   'boxes': array([[10., 10., 50., 50.]], dtype=float32),\n",
       "   'labels': array([[1, 0]], dtype=int32)}])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_predictions_to_metric_format(boxes, scores, labels, image_id, gt_boxes, gt_labels, gt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3589ab-7567-4bd3-9ceb-f81cdd5eb712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
