{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de989763-6707-4f6b-bf54-2fa0bb05ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12101e94-92e9-4a94-ac8b-295b68f4f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import Any\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "import json\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "303a96a2-0b83-4662-8d21-a9c4e060814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilenetv2ssd.core.config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65f280fc-a7a1-4b2b-8b3b-45dea4e948a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cfg_path = \"configs/train/default.yaml\"\n",
    "model_cfg_path = \"configs/model/mobilenetv2_ssd_voc.yaml\"\n",
    "data_cfg_path = \"configs/data/voc_224.yaml\"\n",
    "eval_cfg_path = \"configs/eval/default.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c231636-be18-43ab-ae6a-5805e9bbffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(main_cfg_path,model_cfg_path,data_cfg_path,eval_cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e127c57-d368-47af-9610-df20f3b4d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.base import BaseDetectionDataset, DetectionSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db3a6684-270d-428f-8607-5ff4549e8196",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOCDataset(BaseDetectionDataset):\n",
    "    def __init__(self, root: str | Path, split: str, classes_file: str | Path, use_difficult: bool = False):\n",
    "        super().__init__(root, split, classes_file, use_difficult)\n",
    "\n",
    "        self.jpeg_dir = self.root / \"JPEGImages\"\n",
    "        self.annotation_dir = self.root / \"Annotations\"\n",
    "        self.split_dir = self.root / \"ImageSets\" / \"Main\"\n",
    "\n",
    "        # Validating the directories\n",
    "        self._validate_paths()\n",
    "\n",
    "        self.image_ids = self._load_image_ids()\n",
    "\n",
    "        if len(self.image_ids) == 0:\n",
    "            raise ValueError(f\"No images found for split '{split}'\")\n",
    "        \n",
    "    def _validate_paths(self):\n",
    "        # Checking if the directory exists or not\n",
    "        if not self.jpeg_dir.exists():\n",
    "            raise FileNotFoundError(f\"JPEGImages directory not found: {self.jpeg_dir}\")\n",
    "        \n",
    "        if not self.annotation_dir.exists():\n",
    "            raise FileNotFoundError(f\"Annotations directory not found: {self.annotation_dir}\")\n",
    "\n",
    "        if not self.split_dir.exists():\n",
    "            raise FileNotFoundError(f\"ImageSets/Main directory not found: {self.split_dir}\")\n",
    "\n",
    "    def _load_image_ids(self):\n",
    "        # Loading the ids from the split file to get the proper images\n",
    "        \n",
    "        split_file = self.split_dir / f\"{self.split}.txt\"\n",
    "        \n",
    "        if not split_file.exists():\n",
    "            raise FileNotFoundError(f\"Split file not found: {split_file}\")\n",
    "\n",
    "        with open(split_file, \"r\") as file:\n",
    "            ids = []\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    parts = line.split()\n",
    "                    ids.append(parts[0])\n",
    "\n",
    "        return ids\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def _load_image(self, path: Path):\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"Image not found: {path}\")\n",
    "\n",
    "        # Read the file\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        return np.array(image, dtype = np.float32)\n",
    "\n",
    "    def _parse_annotation(self, path: Path):\n",
    "\n",
    "        if not path.exists():\n",
    "             return np.zeros((0, 4), dtype=np.float32), np.zeros((0,), dtype=np.int32)\n",
    "\n",
    "        # Loading the XML annotation\n",
    "        tree = ET.parse(path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        for obj in root.findall(\"object\"):\n",
    "\n",
    "            # Getting the name\n",
    "            name = (obj.findtext(\"name\") or \"\").strip()\n",
    "            if not name or name not in self.class_to_index:\n",
    "                continue\n",
    "\n",
    "            # Getting the difficult flag\n",
    "            difficult = int(obj.findtext(\"difficult\") or \"0\")\n",
    "            if difficult and not self.use_difficult:\n",
    "                continue\n",
    "\n",
    "            # Getting the bounding box\n",
    "            bbox = obj.find(\"bndbox\")\n",
    "            if bbox is None:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                x1 = float(bbox.findtext(\"xmin\") or 0)\n",
    "                y1 = float(bbox.findtext(\"ymin\") or 0)\n",
    "                x2 = float(bbox.findtext(\"xmax\") or 0)\n",
    "                y2 = float(bbox.findtext(\"ymax\") or 0)\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "\n",
    "            # Making sure invalid boxes dont make it through\n",
    "            if x2 <= x1 or y2 <= y1:\n",
    "                continue\n",
    "\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "            labels.append(self.class_to_index[name])\n",
    "\n",
    "        if boxes:\n",
    "            return np.array(boxes, dtype= np.float32), np.array(labels, dtype=np.int32)\n",
    "        else:\n",
    "            return np.zeros((0, 4), dtype=np.float32), np.zeros((0,), dtype=np.int32)\n",
    "\n",
    "    def _load_sample(self, index: int):\n",
    "        \n",
    "        image_id = self.image_ids[index]\n",
    "\n",
    "        # Loading the image\n",
    "        image_path = self.jpeg_dir / f\"{image_id}.jpg\"\n",
    "        image = self._load_image(image_path)\n",
    "\n",
    "        # Loading the annotation\n",
    "        annotation_path = self.annotation_dir / f\"{image_id}.xml\"\n",
    "        boxes, labels = self._parse_annotation(annotation_path)\n",
    "\n",
    "        return DetectionSample(\n",
    "            image = image, \n",
    "            boxes = boxes,\n",
    "            labels = labels,\n",
    "            image_id = image_id,\n",
    "            path = str(image_path),\n",
    "            orig_size = image.shape[:2]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cdb5eab1-77c1-4302-a3ad-e700e9ec5906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/d/dev/MobileNetV2-SSD/datasets/VOCdevkit/labels/voc_labels.txt'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['data']['classes_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "019dcd68-aff1-4f56-9c01-e39999110b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.VOCDataset at 0x79c38034e620>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCDataset(root = config['data']['root'], split = \"train\", classes_file = config['data']['classes_file'], use_difficult = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a69a9bd-2152-4f44-a02d-4f964bee74e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = VOCDataset(root = config['data']['root'], split = \"train\", classes_file = config['data']['classes_file'], use_difficult = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "944c230e-54a5-453b-9af8-799927f0b5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aeroplane',\n",
       " 'bicycle',\n",
       " 'bird',\n",
       " 'boat',\n",
       " 'bottle',\n",
       " 'bus',\n",
       " 'car',\n",
       " 'cat',\n",
       " 'chair',\n",
       " 'cow',\n",
       " 'diningtable',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'motorbike',\n",
       " 'person',\n",
       " 'pottedplant',\n",
       " 'sheep',\n",
       " 'sofa',\n",
       " 'train',\n",
       " 'tvmonitor']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2d58cb4-19ab-401f-ba09-40df55510cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetectionSample(image=array([[[ 82., 108., 131.],\n",
       "        [ 87., 113., 136.],\n",
       "        [ 93., 120., 141.],\n",
       "        ...,\n",
       "        [160., 105.,  51.],\n",
       "        [160., 105.,  51.],\n",
       "        [158., 103.,  49.]],\n",
       "\n",
       "       [[ 89., 115., 138.],\n",
       "        [ 91., 117., 140.],\n",
       "        [ 91., 118., 139.],\n",
       "        ...,\n",
       "        [159., 104.,  50.],\n",
       "        [158., 103.,  49.],\n",
       "        [155., 100.,  46.]],\n",
       "\n",
       "       [[ 93., 119., 142.],\n",
       "        [ 91., 117., 140.],\n",
       "        [ 87., 114., 135.],\n",
       "        ...,\n",
       "        [158., 103.,  49.],\n",
       "        [155., 100.,  46.],\n",
       "        [152.,  97.,  43.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 46.,  40.,  50.],\n",
       "        [ 40.,  33.,  41.],\n",
       "        [ 32.,  22.,  31.],\n",
       "        ...,\n",
       "        [ 43.,  12.,   7.],\n",
       "        [ 46.,  15.,  10.],\n",
       "        [ 49.,  18.,  13.]],\n",
       "\n",
       "       [[ 53.,  47.,  59.],\n",
       "        [ 48.,  42.,  52.],\n",
       "        [ 50.,  43.,  51.],\n",
       "        ...,\n",
       "        [ 48.,  15.,  10.],\n",
       "        [ 51.,  18.,  13.],\n",
       "        [ 54.,  21.,  16.]],\n",
       "\n",
       "       [[ 63.,  57.,  71.],\n",
       "        [ 57.,  51.,  63.],\n",
       "        [ 65.,  55.,  66.],\n",
       "        ...,\n",
       "        [ 59.,  26.,  21.],\n",
       "        [ 63.,  30.,  25.],\n",
       "        [ 67.,  34.,  29.]]], dtype=float32), boxes=array([[270.,   1., 378., 176.],\n",
       "       [ 57.,   1., 164., 150.]], dtype=float32), labels=array([5, 5], dtype=int32), image_id='2008_000015', path='/mnt/d/dev/MobileNetV2-SSD/datasets/VOCdevkit/VOC2012/JPEGImages/2008_000015.jpg', orig_size=(327, 500))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data._load_sample(index = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8500b4f8-49fc-40cf-b0ef-db15729742c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5717"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92002a2f-0a2b-4f05-a2fa-ea4584aa6955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetectionSample(image=array([[[ 46.,  44.,  32.],\n",
       "        [ 47.,  48.,  32.],\n",
       "        [ 44.,  46.,  32.],\n",
       "        ...,\n",
       "        [ 14.,  23.,  30.],\n",
       "        [ 12.,  20.,  22.],\n",
       "        [ 15.,  23.,  25.]],\n",
       "\n",
       "       [[ 39.,  39.,  29.],\n",
       "        [ 22.,  26.,  11.],\n",
       "        [ 13.,  24.,   7.],\n",
       "        ...,\n",
       "        [  6.,  11.,  17.],\n",
       "        [  6.,  15.,  20.],\n",
       "        [  9.,  23.,  32.]],\n",
       "\n",
       "       [[ 10.,  17.,  10.],\n",
       "        [ 19.,  27.,  14.],\n",
       "        [ 23.,  31.,  18.],\n",
       "        ...,\n",
       "        [ 68.,  73.,  69.],\n",
       "        [ 19.,  22.,  13.],\n",
       "        [ 12.,  21.,  16.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[106., 104., 109.],\n",
       "        [111., 113., 110.],\n",
       "        [108., 113., 106.],\n",
       "        ...,\n",
       "        [ 12.,   8.,   7.],\n",
       "        [ 12.,  11.,   9.],\n",
       "        [ 10.,   9.,   5.]],\n",
       "\n",
       "       [[106., 106., 108.],\n",
       "        [111., 113., 110.],\n",
       "        [105., 112., 105.],\n",
       "        ...,\n",
       "        [ 12.,   9.,   2.],\n",
       "        [ 13.,  10.,   3.],\n",
       "        [ 11.,  11.,   3.]],\n",
       "\n",
       "       [[109., 109., 111.],\n",
       "        [107., 112., 106.],\n",
       "        [108., 115., 108.],\n",
       "        ...,\n",
       "        [ 14.,  11.,   2.],\n",
       "        [ 15.,  12.,   3.],\n",
       "        [ 16.,  13.,   4.]]], dtype=float32), boxes=array([[ 54.,   2., 500., 375.]], dtype=float32), labels=array([12], dtype=int32), image_id='2008_000053', path='/mnt/d/dev/MobileNetV2-SSD/datasets/VOCdevkit/VOC2012/JPEGImages/2008_000053.jpg', orig_size=(375, 500))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data._load_sample(index = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "204541dc-2d95-40a6-80d3-47d2234e1cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_voc_dataset_config( root: str | Path,split: str,classes_file: str | Path,use_difficult: bool = False,):\n",
    "\n",
    "    return VOCDataset(root = root, split = split, classes_file = classes_file, use_difficult = use_difficult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9a6d9e5-53fb-4bc6-9d72-d51e41bc8d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_voc_dataset_config(root = config['data']['root'], split = \"train\", classes_file = config['data']['classes_file'], use_difficult = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b2b755b-614c-44f0-819f-1dd84a246fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetectionSample(image=array([[[ 82., 108., 131.],\n",
       "        [ 87., 113., 136.],\n",
       "        [ 93., 120., 141.],\n",
       "        ...,\n",
       "        [160., 105.,  51.],\n",
       "        [160., 105.,  51.],\n",
       "        [158., 103.,  49.]],\n",
       "\n",
       "       [[ 89., 115., 138.],\n",
       "        [ 91., 117., 140.],\n",
       "        [ 91., 118., 139.],\n",
       "        ...,\n",
       "        [159., 104.,  50.],\n",
       "        [158., 103.,  49.],\n",
       "        [155., 100.,  46.]],\n",
       "\n",
       "       [[ 93., 119., 142.],\n",
       "        [ 91., 117., 140.],\n",
       "        [ 87., 114., 135.],\n",
       "        ...,\n",
       "        [158., 103.,  49.],\n",
       "        [155., 100.,  46.],\n",
       "        [152.,  97.,  43.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 46.,  40.,  50.],\n",
       "        [ 40.,  33.,  41.],\n",
       "        [ 32.,  22.,  31.],\n",
       "        ...,\n",
       "        [ 43.,  12.,   7.],\n",
       "        [ 46.,  15.,  10.],\n",
       "        [ 49.,  18.,  13.]],\n",
       "\n",
       "       [[ 53.,  47.,  59.],\n",
       "        [ 48.,  42.,  52.],\n",
       "        [ 50.,  43.,  51.],\n",
       "        ...,\n",
       "        [ 48.,  15.,  10.],\n",
       "        [ 51.,  18.,  13.],\n",
       "        [ 54.,  21.,  16.]],\n",
       "\n",
       "       [[ 63.,  57.,  71.],\n",
       "        [ 57.,  51.,  63.],\n",
       "        [ 65.,  55.,  66.],\n",
       "        ...,\n",
       "        [ 59.,  26.,  21.],\n",
       "        [ 63.,  30.,  25.],\n",
       "        [ 67.,  34.,  29.]]], dtype=float32), boxes=array([[270.,   1., 378., 176.],\n",
       "       [ 57.,   1., 164., 150.]], dtype=float32), labels=array([5, 5], dtype=int32), image_id='2008_000015', path='/mnt/d/dev/MobileNetV2-SSD/datasets/VOCdevkit/VOC2012/JPEGImages/2008_000015.jpg', orig_size=(327, 500))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b3729-e85f-4518-bbb8-d7697a43b9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
