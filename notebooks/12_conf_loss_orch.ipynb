{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f36fcfa-9499-40a7-936c-7d72a4bcb6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a3c9e4e-3ebe-40e9-aead-aaa4c0a55910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 19:44:25.621227: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-29 19:44:25.639825: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-29 19:44:25.645081: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-29 19:44:25.659636: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-29 19:44:26.625050: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd1f610c-392a-4b7e-a070-0f344fcfd8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilenetv2ssd.core.config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bfdaa9e-830f-45e5-adbd-1d137a37b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4ceec64-385d-40b7-a6a9-63334a9898d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilenetv2ssd.models.ssd.ops.loss_ops_tf import softmax_cross_entropy_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0794a8b-ad4d-4e3d-9f85-8e0424e7763a",
   "metadata": {},
   "source": [
    "## Config Files To Test Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14c664ee-2ac6-4eb5-90f0-0c44323487ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cfg_path = \"configs/train/default.yaml\"\n",
    "model_cfg_path = \"configs/model/mobilenetv2_ssd_voc.yaml\"\n",
    "data_cfg_path = \"configs/data/voc_224.yaml\"\n",
    "eval_cfg_path = \"configs/eval/default.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4201a19a-e934-40d0-bbff-ae420b20215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(main_cfg_path,model_cfg_path,data_cfg_path,eval_cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c7c5a5e-6086-4338-b4ef-a1e7e18927d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment': {'name': 'voc_mnv2_baseline',\n",
       "  'description': 'MobileNetV2-SSD baseline on PASCAL VOC 224x224',\n",
       "  'tags': ['ssd', 'mobilenetv2', 'voc', 'baseline']},\n",
       " 'include': {'model_cfg': 'configs/model/mobilenetv2_ssd_voc.yaml',\n",
       "  'data_cfg': 'configs/data/voc_224.yaml',\n",
       "  'eval_cfg': 'configs/eval/default.yaml'},\n",
       " 'train': {'seed': 1337,\n",
       "  'device': 'auto',\n",
       "  'epochs': 50,\n",
       "  'batch_size': 3,\n",
       "  'grad_accum_steps': 1,\n",
       "  'optimizer': {'name': 'sgd',\n",
       "   'lr': 0.001,\n",
       "   'momentum': 0.9,\n",
       "   'weight_decay': 0.0005,\n",
       "   'nesterov': True},\n",
       "  'scheduler': {'name': 'cosine', 'warmup': {'epochs': 5, 'factor': 0.1}},\n",
       "  'loss': {'cls_loss_type': 'softmax_ce',\n",
       "   'from_logits': True,\n",
       "   'ignore_index': -1,\n",
       "   'label_smoothing': 0.0,\n",
       "   'use_sigmoid': False,\n",
       "   'class_weights': None,\n",
       "   'reg_loss_type': 'smooth_l1',\n",
       "   'smooth_l1_beta': 1.0,\n",
       "   'bbox_norm': 'none',\n",
       "   'alpha': 1.0,\n",
       "   'gamma': 2.0,\n",
       "   'cls_weight': 1.0,\n",
       "   'reg_weight': 1.0,\n",
       "   'reduction': 'sum',\n",
       "   'normalization': {'type': 'num_pos', 'epsilon': '1e-6'}},\n",
       "  'sampler': {'neg_pos_ratio': 3.0, 'min_neg': 0, 'max_neg': None},\n",
       "  'targets': {'filters': {'min_box_area': 0.0,\n",
       "    'clip_to_image': True,\n",
       "    'drop_invalid': True}},\n",
       "  'diagnostics': False},\n",
       " 'logging': {'runs_root': 'runs',\n",
       "  'run_name_suffix': '',\n",
       "  'log_interval_steps': 50,\n",
       "  'val_interval_epochs': 1,\n",
       "  'checkpoint': {'dir': 'checkpoints',\n",
       "   'save_best_only': True,\n",
       "   'monitor': 'val_map',\n",
       "   'mode': 'max',\n",
       "   'keep_last': 5},\n",
       "  'wandb': {'enabled': False,\n",
       "   'project': 'mobilenetv2-ssd',\n",
       "   'entity': None,\n",
       "   'group': None}},\n",
       " 'runtime': {'num_workers': 4,\n",
       "  'prefetch_batches': 2,\n",
       "  'mixed_precision': 'none',\n",
       "  'deterministic': False},\n",
       " 'export': {'save_final_checkpoint': True,\n",
       "  'save_best_checkpoint': True,\n",
       "  'export_saved_model': True,\n",
       "  'export_onnx': False,\n",
       "  'export_tflite': False},\n",
       " 'model': {'name': 'mobilenetv2-ssd',\n",
       "  'backbone': 'mobilenetv2',\n",
       "  'width_mult': 1.0,\n",
       "  'num_classes': 21,\n",
       "  'input_size': [224, 224],\n",
       "  'feature_maps': ['C3', 'C4', 'C5', 'P6', 'P7', 'P8'],\n",
       "  'priors': {'image_size': [224, 224],\n",
       "   'strides': [8, 16, 32, 64, 128, 224],\n",
       "   'aspect_ratios': [[1.0, 2.0, 0.5],\n",
       "    [1.0, 2.0, 0.5, 3.0, 0.3333],\n",
       "    [1.0, 2.0, 0.5, 3.0, 0.3333],\n",
       "    [1.0, 2.0, 0.5],\n",
       "    [1.0, 2.0, 0.5],\n",
       "    [1.0, 2.0, 0.5]],\n",
       "   'min_scale': 0.2,\n",
       "   'max_scale': 0.95,\n",
       "   'variances': [0.1, 0.2]},\n",
       "  'matcher': {'iou_threshold_pos': 0.5,\n",
       "   'iou_threshold_neg': 0.4,\n",
       "   'allow_low_quality_matches': False,\n",
       "   'center_in_gt': False},\n",
       "  'sampler': {'neg_pos_ratio': 3.0, 'min_neg': 0, 'max_neg': None},\n",
       "  'heads': {'norm_cfg': 'batch_norm',\n",
       "   'head_type': 'conv3x3',\n",
       "   'intermediate_channels': 256,\n",
       "   'squeeze_ratio': 1.0,\n",
       "   'use_sigmoid_cls': False},\n",
       "  'loss': {'cls_loss_type': 'focal',\n",
       "   'reg_loss_type': 'smooth_l1',\n",
       "   'background_class_weight': 1.0}},\n",
       " 'data': {'dataset_name': 'voc',\n",
       "  'root': 'datasets/VOCdevkit',\n",
       "  'train_split': 'trainval',\n",
       "  'val_split': 'test',\n",
       "  'input_size': [224, 224],\n",
       "  'num_workers': 4,\n",
       "  'shuffle_buffer': 1000,\n",
       "  'prefetch_batches': 2,\n",
       "  'augment': {'random_flip': True,\n",
       "   'random_flip_prob': 0.5,\n",
       "   'random_crop': True,\n",
       "   'min_crop_iou_choices': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
       "   'min_crop_scale': 0.3,\n",
       "   'max_crop_scale': 1.0,\n",
       "   'photometric_distort': True,\n",
       "   'photometric_distort_prob': 0.5},\n",
       "  'normalization': {'mean': [0.485, 0.456, 0.406],\n",
       "   'std': [0.229, 0.224, 0.225]},\n",
       "  'classes_file': 'configs/data/voc_classes.txt'},\n",
       " 'eval': {'dataset_split': 'val',\n",
       "  'nms': {'iou_threshold': 0.5,\n",
       "   'score_threshold': 0.05,\n",
       "   'max_detections_per_image': 100,\n",
       "   'max_detections_per_class': 50},\n",
       "  'metrics': {'type': 'voc_ap',\n",
       "   'iou_thresholds': [0.5],\n",
       "   'use_07_metric': False},\n",
       "  'visualization': {'enabled': False,\n",
       "   'max_images': 16,\n",
       "   'output_dir': 'eval_vis'}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc01312-7089-4cae-a7e9-ad6c4c7d4ae7",
   "metadata": {},
   "source": [
    "## Helper Functions For Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37dd9cb2-f39c-4c16-b23b-c05aa4bd9e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_information_from_train_config(config : dict[str, Any]):\n",
    "    train_config = config['train']\n",
    "    loss_config = train_config.get(\"loss\",{})\n",
    "    loss_config = {\n",
    "        \"cls_loss_type\": loss_config.get(\"cls_loss_type\",\"ce_softmax\"),\n",
    "        \"from_logits\": loss_config.get(\"from_logits\",False),\n",
    "        \"ignore_index\": loss_config.get(\"ignore_index\",-1),\n",
    "        \"use_sigmoid\": loss_config.get(\"use_sigmoid\",False),\n",
    "    }\n",
    "\n",
    "    return loss_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48a8f7c1-b0ee-4a9b-8b96-ec4d329f873f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cls_loss_type': 'softmax_ce',\n",
       " 'from_logits': True,\n",
       " 'ignore_index': -1,\n",
       " 'use_sigmoid': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_extract_information_from_train_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6997d42-7423-4767-8d82-71ac888cbe39",
   "metadata": {},
   "source": [
    "## Orchestration Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8defe275-0409-4fcc-966a-75a3494d489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conf_loss(config: dict[str,Any], predicted_logits: tf.Tensor, classification_targets: tf.Tensor, pos_mask: tf.Tensor, neg_mask: tf.Tensor, ignore_mask: tf.Tensor):\n",
    "    # This is the orchestrator to calculate the confidence loss between the priors and the matched boxes\n",
    "    # Steps:\n",
    "    # 1. Get the config for the loss\n",
    "    # 2. Calculate the valid mask (Safeguard, my model should remove it already)\n",
    "    # 3. Calculate the classification loss per anchor\n",
    "    # 4. Apply label smoothing (Optional Implementation)\n",
    "    # 5. Multiply Class wieights (Optional Implementation)\n",
    "    \n",
    "    loss_config = _extract_information_from_train_config(config)\n",
    "\n",
    "    candidate_negative_mask = tf.logical_and(neg_mask,tf.logical_not(ignore_mask))\n",
    "    ignored_labels = tf.zeros_like(classification_targets)\n",
    "\n",
    "    valid_labels = tf.where(tf.logical_not(ignore_mask),classification_targets,ignored_labels)\n",
    "\n",
    "    if loss_config['cls_loss_type'] == 'softmax_ce':\n",
    "        per_class_loss = tf.map_fn(lambda inputs: softmax_cross_entropy_loss(inputs[0],inputs[1],reduction=\"none\"),\n",
    "                 elems = (predicted_logits, valid_labels),\n",
    "                 fn_output_signature = tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
    "                 )\n",
    "\n",
    "\n",
    "    # Handle NaN\n",
    "    nan = tf.constant(float(\"nan\"), dtype = per_class_loss.dtype)\n",
    "\n",
    "    conf_loss = tf.where(tf.logical_not(ignore_mask), per_class_loss, tf.fill(tf.shape(per_class_loss), nan))\n",
    "\n",
    "\n",
    "    return conf_loss, candidate_negative_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86348a35-7008-4131-8498-4319ab6b40a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764463468.090479   84456 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764463468.189310   84456 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764463468.189506   84456 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764463468.193628   84456 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764463468.193785   84456 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764463468.193854   84456 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764463468.396787   84456 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764463468.396922   84456 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-29 19:44:28.396936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-11-29 19:44:28.396983: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:198] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1764463468.397242   84456 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-29 19:44:28.397277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "pred_logits_b = tf.constant(\n",
    "    [\n",
    "        # -------- image 0 (same as above) --------\n",
    "        [[ 2.0, -1.0,  0.5,  0.0],   # 0\n",
    "         [ 0.1,  2.0, -0.5, -1.0],   # 1 (pos class 1)\n",
    "         [ 1.5, -0.2,  0.0, -0.3],   # 2\n",
    "         [-0.5,  0.2,  2.5,  0.1],   # 3 (pos class 2)\n",
    "         [ 0.0,  0.0,  0.0,  0.0],   # 4 ignored\n",
    "         [ 2.5,  0.1, -0.2,  0.3]],  # 5\n",
    "\n",
    "        # -------- image 1 (different distribution) --------\n",
    "        [[ 0.3,  1.8, -0.5,  0.0],   # 0 (pos class 1)\n",
    "         [ 2.2, -0.1,  0.1, -0.8],   # 1 background\n",
    "         [ 0.0,  0.0,  0.0,  0.0],   # 2 ignored\n",
    "         [ 0.1, -0.2,  2.0,  0.3],   # 3 (pos class 2)\n",
    "         [ 1.2,  0.4, -0.3, -0.5],   # 4 background\n",
    "         [ 0.5,  0.7,  0.2, -0.1]]   # 5 background\n",
    "    ],\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "cls_targets_b = tf.constant(\n",
    "    [\n",
    "        # image 0\n",
    "        [0, 1, 0, 2, -1, 0],\n",
    "        # image 1\n",
    "        [1, 0, -1, 2, 0, 0],\n",
    "    ],\n",
    "    dtype=tf.int32\n",
    ")\n",
    "\n",
    "\n",
    "pos_mask_b = tf.constant(\n",
    "    [\n",
    "        # image 0: priors 1, 3\n",
    "        [False, True,  False, True,  False, False],\n",
    "        # image 1: priors 0, 3\n",
    "        [True,  False, False, True,  False, False],\n",
    "    ],\n",
    "    dtype=tf.bool\n",
    ")\n",
    "\n",
    "neg_mask_b = tf.constant(\n",
    "    [\n",
    "        # image 0: raw negatives at 0,2,5\n",
    "        [True,  False, True,  False, False, True],\n",
    "        # image 1: raw negatives at 1,4,5 (2 is ignored)\n",
    "        [False, True,  False, False, True,  True],\n",
    "    ],\n",
    "    dtype=tf.bool\n",
    ")\n",
    "\n",
    "ignore_mask_b = tf.constant(\n",
    "    [\n",
    "        # image 0: prior 4 ignored\n",
    "        [False, False, False, False, True,  False],\n",
    "        # image 1: prior 2 ignored\n",
    "        [False, False, True,  False, False, False],\n",
    "    ],\n",
    "    dtype=tf.bool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80b7ada9-b7f9-44c8-b653-3b43309dc839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 6), dtype=float32, numpy=\n",
       " array([[0.34234956, 0.24798493, 0.45178396, 0.21572715,        nan,\n",
       "         0.23801371],\n",
       "        [0.3978952 , 0.24098527,        nan, 0.36676258, 0.6179616 ,\n",
       "         1.2559102 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 6), dtype=bool, numpy=\n",
       " array([[ True, False,  True, False, False,  True],\n",
       "        [False,  True, False, False,  True,  True]])>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_conf_loss(config,pred_logits_b,cls_targets_b,pos_mask_b,neg_mask_b,ignore_mask_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7bb910-0409-4d74-afc7-ea97d5384ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
