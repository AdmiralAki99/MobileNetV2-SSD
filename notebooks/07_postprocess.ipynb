{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f58a42a-fef1-4fe3-8129-2cecead5007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Iterable, Literal, overload\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f1535fa-d7b0-4dcb-a47e-91ce04936118",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88fdfc1c-167e-488f-a641-5f8b6a6d655c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 22:08:21.485619: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-17 22:08:21.506332: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-17 22:08:21.512274: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-17 22:08:21.526329: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-17 22:08:22.449428: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3c62ece-78fa-4d0d-9b49-9ec9da2001ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _decode_boxes(predicted_offsets: tf.Tensor, priors: tf.Tensor, variances: tf.Tensor):\n",
    "    B = tf.shape(predicted_offsets)[0]\n",
    "    N = tf.shape(predicted_offsets)[1]\n",
    "\n",
    "    # Variance size\n",
    "    variance_center = variances[0]\n",
    "    variance_shape = variances[1]\n",
    "    \n",
    "    # Broadcasting the priors to the shape for the offsets\n",
    "    broadcasted_priors = tf.broadcast_to(priors[tf.newaxis,...],[B,N,4])\n",
    "\n",
    "    # Decoding the boxes\n",
    "    tx,ty,tw,th = tf.split(predicted_offsets,num_or_size_splits = 4, axis=-1)\n",
    "    cx,cy,w,h = tf.split(broadcasted_priors,num_or_size_splits = 4, axis=-1)\n",
    "\n",
    "    # Adding the offset to the coordinates\n",
    "    cx = cx + tx * variance_center * w\n",
    "    cy = cy + ty * variance_center * h\n",
    "    w = w * tf.math.exp(tw * variance_shape)\n",
    "    h = h * tf.math.exp(th * variance_shape)\n",
    "\n",
    "    # Converting the boxes to xy-coordinates\n",
    "    x_min = cx - w/2\n",
    "    y_min = cy - h/2\n",
    "    x_max = cx + w/2\n",
    "    y_max = cy + h/2\n",
    "\n",
    "    boxes_xyxy = tf.concat([x_min, y_min, x_max, y_max],axis=-1)\n",
    "\n",
    "    boxes_xyxy = tf.clip_by_value(boxes_xyxy,0,1)\n",
    "\n",
    "    return boxes_xyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e62fde36-c6ad-4b8f-9352-8769a03009e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763435303.236224   96181 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1763435303.324594   96181 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1763435303.324702   96181 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1763435303.326014   96181 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1763435303.326075   96181 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1763435303.326110   96181 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1763435303.519922   96181 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1763435303.520009   96181 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-17 22:08:23.520022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-11-17 22:08:23.520047: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:198] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1763435303.520386   96181 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-17 22:08:23.520430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "pred_loc = tf.constant(\n",
    "    [[[0.0,  0.0,  0.0,  0.0],   # offsets for prior 0\n",
    "      [0.5, -0.5,  0.3, -0.2]]], # offsets for prior 1\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "priors = tf.constant(\n",
    "    [[0.50, 0.50, 0.20, 0.40],   # (cx, cy, w, h) prior 0\n",
    "     [0.25, 0.75, 0.10, 0.20]],  # prior 1\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "variances = tf.constant([0.1, 0.2], dtype=tf.float32)\n",
    "\n",
    "min_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb36a343-92bf-4088-a364-3aa134c4f33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 4), dtype=float32, numpy=\n",
       "array([[[ 0. ,  0. ,  0. ,  0. ],\n",
       "        [ 0.5, -0.5,  0.3, -0.2]]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fe8b8a5-8135-4168-ab4e-7c78b44dc050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 4), dtype=float32, numpy=\n",
       "array([[[0.4       , 0.3       , 0.6       , 0.7       ],\n",
       "        [0.20190817, 0.6439211 , 0.30809182, 0.83607894]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_decode_boxes(pred_loc,priors,variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20339c51-c58b-4bf1-90c7-a59f4555f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _softmax_probabilities(logits: tf.Tensor):\n",
    "    logits = tf.cast(logits, tf.float32)\n",
    "\n",
    "    max_per_row = tf.reduce_max(logits, axis=-1, keepdims=True)\n",
    "    shifted_logits = logits - max_per_row\n",
    "\n",
    "    exponential_shifted_logits = tf.math.exp(shifted_logits)\n",
    "    sum_exponential_shifted_logits = tf.reduce_sum(exponential_shifted_logits, axis=-1, keepdims=True)\n",
    "\n",
    "    softmax_probs = exponential_shifted_logits / sum_exponential_shifted_logits\n",
    "\n",
    "    return softmax_probs\n",
    "\n",
    "def _sigmoid_probabilities(logits: tf.Tensor):\n",
    "    logits = tf.cast(logits, tf.float32)\n",
    "\n",
    "    sigmoid_probabilities = 1/(1 + tf.math.exp(-logits))\n",
    "\n",
    "    return sigmoid_probabilities\n",
    "    \n",
    "\n",
    "def _score_from_logits(predicted_logits: tf.Tensor, scores_thresh: float, use_sigmoid: bool = True):\n",
    "    if use_sigmoid:\n",
    "        sigmoid_probs = _sigmoid_probabilities(predicted_logits)\n",
    "\n",
    "        thresh_mask = sigmoid_probs < scores_thresh\n",
    "\n",
    "        thresholded_scores = tf.where(thresh_mask, tf.zeros_like(sigmoid_probs), sigmoid_probs)\n",
    "    else:\n",
    "        softmax_probs = _softmax_probabilities(predicted_logits)\n",
    "        scores = softmax_probs[...,1:]\n",
    "\n",
    "        # Applying the threshold\n",
    "        thresh_mask = scores < scores_thresh\n",
    "\n",
    "        # Updating the scores in the tensor\n",
    "        thresholded_scores = tf.where(thresh_mask, tf.zeros_like(scores), scores)\n",
    "    \n",
    "    return thresholded_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b50723ba-20c7-48ca-bafe-7a4b890d9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logits = tf.constant([\n",
    "    [\n",
    "        [ 0.0,  2.0,  0.5, -1.0 ],\n",
    "        [ 1.0, -0.5,  0.0,  0.0 ],\n",
    "        [ 3.0,  3.0,  1.0,  0.0 ]\n",
    "    ]\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ad671ee-50f0-498b-86be-4d3a22cd48bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 4), dtype=float32, numpy=\n",
       "array([[[ 0. ,  2. ,  0.5, -1. ],\n",
       "        [ 1. , -0.5,  0. ,  0. ],\n",
       "        [ 3. ,  3. ,  1. ,  0. ]]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df71c095-263f-4b28-bf51-fc2efed7382e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\n",
       "array([[[0.7100999 , 0.1584447 , 0.        ],\n",
       "        [0.11390647, 0.18780003, 0.18780003],\n",
       "        [0.4576403 , 0.        , 0.        ]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_score_from_logits(pred_logits, 0.1, use_sigmoid = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a3d53d5-cfcd-487e-a85d-2e3e4b66fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logits = tf.constant([\n",
    " [\n",
    "     [ 0.0,  2.0, -1.0 ],\n",
    "     [-0.5,  0.0,  1.0 ]\n",
    " ]   \n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc839c6f-540e-445c-ae93-ad896d31f48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 3), dtype=float32, numpy=\n",
       "array([[[ 0. ,  2. , -1. ],\n",
       "        [-0.5,  0. ,  1. ]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fadae383-8874-4c96-9a5f-1574839c7a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 3), dtype=float32, numpy=\n",
       "array([[[0.5       , 0.880797  , 0.26894143],\n",
       "        [0.37754068, 0.5       , 0.73105854]]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sigmoid_probabilities(pred_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5422cc7-788f-4fad-aa91-687c40e9b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_nms_inputs(boxes_xyxy: tf.Tensor, scores: tf.Tensor):\n",
    "    nms_boxes = boxes_xyxy[:,:,tf.newaxis,:]\n",
    "    nms_scores = scores\n",
    "    \n",
    "    return nms_boxes,nms_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0ef9fad-04a5-4dac-98bd-30ce6cab7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_xyxy = tf.constant([\n",
    "    [  # image 0\n",
    "        [0.10, 0.20, 0.40, 0.60],   # anchor 0\n",
    "        [0.15, 0.25, 0.50, 0.70],   # anchor 1\n",
    "        [0.60, 0.10, 0.90, 0.40],   # anchor 2\n",
    "    ],\n",
    "    [  # image 1\n",
    "        [0.05, 0.30, 0.35, 0.80],   # anchor 0\n",
    "        [0.20, 0.15, 0.55, 0.65],   # anchor 1\n",
    "        [0.55, 0.50, 0.95, 0.95],   # anchor 2\n",
    "    ],\n",
    "])\n",
    "\n",
    "scores = tf.constant([\n",
    "    [  # image 0\n",
    "        [0.80, 0.10],   # anchor 0: mostly class 0\n",
    "        [0.60, 0.40],   # anchor 1: kind of ambiguous\n",
    "        [0.05, 0.90],   # anchor 2: mostly class 1\n",
    "    ],\n",
    "    [  # image 1\n",
    "        [0.20, 0.50],   # anchor 0\n",
    "        [0.70, 0.30],   # anchor 1\n",
    "        [0.10, 0.95],   # anchor 2\n",
    "    ],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f6dd285-86b0-4c39-82f3-098d0cd15bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 3, 1, 4), dtype=float32, numpy=\n",
       " array([[[[0.1 , 0.2 , 0.4 , 0.6 ]],\n",
       " \n",
       "         [[0.15, 0.25, 0.5 , 0.7 ]],\n",
       " \n",
       "         [[0.6 , 0.1 , 0.9 , 0.4 ]]],\n",
       " \n",
       " \n",
       "        [[[0.05, 0.3 , 0.35, 0.8 ]],\n",
       " \n",
       "         [[0.2 , 0.15, 0.55, 0.65]],\n",
       " \n",
       "         [[0.55, 0.5 , 0.95, 0.95]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 3, 2), dtype=float32, numpy=\n",
       " array([[[0.8 , 0.1 ],\n",
       "         [0.6 , 0.4 ],\n",
       "         [0.05, 0.9 ]],\n",
       " \n",
       "        [[0.2 , 0.5 ],\n",
       "         [0.7 , 0.3 ],\n",
       "         [0.1 , 0.95]]], dtype=float32)>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_prepare_nms_inputs(boxes_xyxy,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5acf14cf-4b23-4d37-abb5-90ba7c7a3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_batched_nms(nms_boxes: tf.Tensor, nms_scores: tf.Tensor, iou_thresh: float, scores_thresh: float, top_k: int, max_detections: int):\n",
    "    \n",
    "    nms_boxes, nms_scores, nms_classes, valid_detections = tf.image.combined_non_max_suppression(nms_boxes,nms_scores,top_k,max_detections,iou_threshold= iou_thresh,score_threshold= scores_thresh,clip_boxes=False)\n",
    "\n",
    "    return nms_boxes,nms_scores,nms_classes,valid_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c681ca8f-beb2-4cd7-8807-9059eb1e0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_boxes_xyxy = tf.constant([\n",
    "    [  # image 0\n",
    "        [[0.10, 0.10, 0.40, 0.40]],   # anchor 0\n",
    "        [[0.15, 0.15, 0.45, 0.45]],   # anchor 1\n",
    "        [[0.60, 0.60, 0.90, 0.90]],   # anchor 2\n",
    "    ],\n",
    "])\n",
    "\n",
    "scores = tf.constant([\n",
    "    [  # image 0\n",
    "        [0.90, 0.20],   # anchor 0\n",
    "        [0.80, 0.70],   # anchor 1\n",
    "        [0.10, 0.95],   # anchor 2\n",
    "    ],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52080823-b479-410d-a321-5494b203a5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 1, 4), dtype=float32, numpy=\n",
       "array([[[[0.1 , 0.1 , 0.4 , 0.4 ]],\n",
       "\n",
       "        [[0.15, 0.15, 0.45, 0.45]],\n",
       "\n",
       "        [[0.6 , 0.6 , 0.9 , 0.9 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nms_boxes_xyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77892fba-69e4-4010-8022-2e4b1fbf74a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 2), dtype=float32, numpy=\n",
       "array([[[0.9 , 0.2 ],\n",
       "        [0.8 , 0.7 ],\n",
       "        [0.1 , 0.95]]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "697b13df-bb10-43e7-9c8e-3654f84a5450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 3, 4), dtype=float32, numpy=\n",
       " array([[[0.6 , 0.6 , 0.9 , 0.9 ],\n",
       "         [0.1 , 0.1 , 0.4 , 0.4 ],\n",
       "         [0.15, 0.15, 0.45, 0.45]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[0.95, 0.9 , 0.7 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[1., 0., 1.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([3], dtype=int32)>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_run_batched_nms(nms_boxes_xyxy,scores, 0.5, 0.5, 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7373c296-8fdc-422f-8938-07d92945d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _restore_to_image_space(boxes_yxyx_norm: tf.Tensor, image_height: int, image_width: int):\n",
    "    # Multiplying the normalized coordinates with the \n",
    "    y_min,x_min,y_max,x_max = tf.split(boxes_yxyx_norm,num_or_size_splits = 4, axis=-1)\n",
    "\n",
    "    # Scaling the box back to the image\n",
    "    y_min = y_min * image_height\n",
    "    x_min = x_min * image_width\n",
    "\n",
    "    y_max = y_max * image_height\n",
    "    x_max = x_max * image_width\n",
    "\n",
    "    # Stacking the values back\n",
    "    return tf.concat([x_min,y_min,x_max,y_max], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e69c3d6-721b-4a83-b094-067e86dcf912",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmsed_boxes_norm = tf.constant([\n",
    "    [\n",
    "    [0.40, 0.30, 0.70, 0.60],   # box A\n",
    "    [0.10, 0.55, 0.20, 0.85],   # box B\n",
    "    ]\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd03cf08-72d6-4d11-a7b4-96d202344a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 4), dtype=float32, numpy=\n",
       "array([[[0.4 , 0.3 , 0.7 , 0.6 ],\n",
       "        [0.1 , 0.55, 0.2 , 0.85]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmsed_boxes_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "620e3f05-31c5-42f3-9ce9-ccc3e1a12640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 4), dtype=float32, numpy=\n",
       "array([[[ 90., 120., 180., 210.],\n",
       "        [165.,  30., 255.,  60.]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_restore_to_image_space(nmsed_boxes_norm,300,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a5bbdb5-53eb-466c-bdf2-02c152016f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter_small_boxes(boxes_norm_xyxy: tf.Tensor, scores:tf.Tensor, min_size: float):\n",
    "\n",
    "    # Safety check\n",
    "    if min_size is None or min_size <= 0:\n",
    "         return boxes_norm_xyxy, scores, tf.ones(tf.shape(boxes_norm_xyxy)[:2], dtype=tf.bool)\n",
    "    \n",
    "    # Splitting the coordinates\n",
    "    x_min,y_min,x_max,y_max = tf.split(boxes_norm_xyxy,num_or_size_splits = 4, axis=-1)\n",
    "\n",
    "    # Calculating the width and height\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "\n",
    "    # Masking stuff to keep\n",
    "    keep_mask = (width >= min_size) & (height >= min_size)\n",
    "\n",
    "    # Gathering the box anchors\n",
    "    gathered_anchors = tf.where(keep_mask, boxes_norm_xyxy, tf.zeros_like(boxes_norm_xyxy))\n",
    "\n",
    "    # Gathering the scores\n",
    "    gathered_scores = tf.where(keep_mask, scores, tf.zeros_like(scores))\n",
    "\n",
    "    return gathered_anchors, gathered_scores, keep_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e47707f-532c-46ba-95c8-fdb0a663f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_norm_xyxy = tf.constant([\n",
    "  [  # image 0\n",
    "    [0.10, 0.10, 0.50, 0.50],\n",
    "    [0.20, 0.20, 0.25, 0.23],\n",
    "    [0.00, 0.00, 0.15, 0.50],\n",
    "    [0.80, 0.80, 0.90, 0.82],\n",
    "  ],\n",
    "  [  # image 1\n",
    "    [0.05, 0.05, 0.07, 0.07],\n",
    "    [0.30, 0.30, 0.70, 0.90],\n",
    "    [0.50, 0.10, 0.90, 0.18],\n",
    "    [0.00, 0.50, 0.10, 0.60],\n",
    "  ],\n",
    "])\n",
    "\n",
    "scores = tf.constant(\n",
    "    [\n",
    "  [  # image 0\n",
    "    [0.90, 0.10, 0.05],   # box 0\n",
    "    [0.20, 0.30, 0.40],   # box 1\n",
    "    [0.05, 0.80, 0.60],   # box 2\n",
    "    [0.10, 0.20, 0.90],   # box 3\n",
    "  ],\n",
    "  [  # image 1\n",
    "    [0.05, 0.10, 0.20],   # box 0\n",
    "    [0.90, 0.70, 0.30],   # box 1\n",
    "    [0.40, 0.50, 0.05],   # box 2\n",
    "    [0.10, 0.80, 0.60],   # box 3\n",
    "  ],\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "176b143e-449e-490c-94aa-95566a2e6781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 4, 4), dtype=float32, numpy=\n",
       " array([[[0.1 , 0.1 , 0.5 , 0.5 ],\n",
       "         [0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.15, 0.5 ],\n",
       "         [0.  , 0.  , 0.  , 0.  ]],\n",
       " \n",
       "        [[0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.3 , 0.3 , 0.7 , 0.9 ],\n",
       "         [0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.5 , 0.1 , 0.6 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 4, 3), dtype=float32, numpy=\n",
       " array([[[0.9 , 0.1 , 0.05],\n",
       "         [0.  , 0.  , 0.  ],\n",
       "         [0.05, 0.8 , 0.6 ],\n",
       "         [0.  , 0.  , 0.  ]],\n",
       " \n",
       "        [[0.  , 0.  , 0.  ],\n",
       "         [0.9 , 0.7 , 0.3 ],\n",
       "         [0.  , 0.  , 0.  ],\n",
       "         [0.1 , 0.8 , 0.6 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 4, 1), dtype=bool, numpy=\n",
       " array([[[ True],\n",
       "         [False],\n",
       "         [ True],\n",
       "         [False]],\n",
       " \n",
       "        [[False],\n",
       "         [ True],\n",
       "         [False],\n",
       "         [ True]]])>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_filter_small_boxes(boxes_norm_xyxy,scores,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e977fae2-6a93-428c-91f0-4662fe0d8e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 3), dtype=float32, numpy=\n",
       "array([[[0.9 , 0.1 , 0.05],\n",
       "        [0.2 , 0.3 , 0.4 ],\n",
       "        [0.05, 0.8 , 0.6 ],\n",
       "        [0.1 , 0.2 , 0.9 ]],\n",
       "\n",
       "       [[0.05, 0.1 , 0.2 ],\n",
       "        [0.9 , 0.7 , 0.3 ],\n",
       "        [0.4 , 0.5 , 0.05],\n",
       "        [0.1 , 0.8 , 0.6 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bbae37e-192b-434c-a40d-3d1b5aa2d4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_xyxy = tf.constant([\n",
    "  [\n",
    "    [0.10, 0.10, 0.20, 0.20],  # anchor 0\n",
    "    [0.15, 0.15, 0.30, 0.30],  # anchor 1\n",
    "    [0.40, 0.40, 0.60, 0.60],  # anchor 2\n",
    "    [0.05, 0.50, 0.25, 0.70],  # anchor 3\n",
    "    [0.60, 0.10, 0.90, 0.40],  # anchor 4\n",
    "  ],\n",
    "   [\n",
    "    [0.05, 0.05, 0.15, 0.15],  # anchor 0\n",
    "    [0.20, 0.20, 0.40, 0.40],  # anchor 1\n",
    "    [0.45, 0.45, 0.65, 0.65],  # anchor 2\n",
    "    [0.10, 0.60, 0.30, 0.80],  # anchor 3\n",
    "    [0.55, 0.20, 0.85, 0.50],  # anchor 4\n",
    "  ]\n",
    "])\n",
    "\n",
    "scores = tf.constant([\n",
    "     [\n",
    "    [0.90, 0.10, 0.05],  # anchor 0\n",
    "    [0.20, 0.15, 0.10],  # anchor 1\n",
    "    [0.50, 0.30, 0.25],  # anchor 2\n",
    "    [0.80, 0.60, 0.40],  # anchor 3\n",
    "    [0.10, 0.05, 0.02],  # anchor 4\n",
    "  ],\n",
    "    [\n",
    "    [0.10, 0.05, 0.02],  # anchor 0\n",
    "    [0.95, 0.80, 0.60],  # anchor 1\n",
    "    [0.60, 0.55, 0.50],  # anchor 2\n",
    "    [0.40, 0.20, 0.10],  # anchor 3\n",
    "    [0.70, 0.65, 0.30],  # anchor 4\n",
    "  ]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e14ade1b-daf8-4edd-b809-cf4b2ff90f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pre_nms_top_k(boxes_xyxy: tf.Tensor, scores: tf.Tensor, top_k: int):\n",
    "\n",
    "    tf.debugging.assert_equal(tf.shape(boxes_xyxy)[-1], 4)\n",
    "    tf.debugging.assert_equal(tf.shape(boxes_xyxy)[1], tf.shape(scores)[1])\n",
    "\n",
    "    boxes_xyxy = tf.cast(boxes_xyxy,tf.float32)\n",
    "    scores = tf.cast(scores,tf.float32)\n",
    "\n",
    "    N = tf.shape(boxes_xyxy)[1]\n",
    "\n",
    "    top_k = tf.minimum(N,top_k)\n",
    "\n",
    "    # Max scores\n",
    "    max_scores = tf.reduce_max(scores,axis=-1)\n",
    "\n",
    "    # Get top k scores\n",
    "    _, top_k_indices = tf.math.top_k(max_scores,k=top_k)\n",
    "\n",
    "    # Get the top k boxes\n",
    "    boxes_top_k = tf.gather(boxes_xyxy,top_k_indices, batch_dims = 1)\n",
    "\n",
    "    # Gathering all the scores associated with the indices\n",
    "    scores_top_k = tf.gather(scores,top_k_indices, batch_dims = 1)\n",
    "\n",
    "    return boxes_top_k, scores_top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56cbaa96-1add-40bb-ad8a-d3c684ff5e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       " array([[[0.1 , 0.1 , 0.2 , 0.2 ],\n",
       "         [0.05, 0.5 , 0.25, 0.7 ],\n",
       "         [0.4 , 0.4 , 0.6 , 0.6 ]],\n",
       " \n",
       "        [[0.2 , 0.2 , 0.4 , 0.4 ],\n",
       "         [0.55, 0.2 , 0.85, 0.5 ],\n",
       "         [0.45, 0.45, 0.65, 0.65]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=\n",
       " array([[[0.9 , 0.1 , 0.05],\n",
       "         [0.8 , 0.6 , 0.4 ],\n",
       "         [0.5 , 0.3 , 0.25]],\n",
       " \n",
       "        [[0.95, 0.8 , 0.6 ],\n",
       "         [0.7 , 0.65, 0.3 ],\n",
       "         [0.6 , 0.55, 0.5 ]]], dtype=float32)>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pre_nms_top_k(boxes_xyxy,scores,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ac72222-3f8f-4b58-8801-cafbc40294b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_and_nms(predicted_offsets: tf.Tensor, predicted_logits: tf.Tensor, priors: tf.Tensor, variances: tf.Tensor, scores_thresh: float, iou_thresh: float, top_k: int, max_detections: int, image_meta: dict| None, use_sigmoid: bool = False, **kwargs):\n",
    "    # Decoding the boxes\n",
    "    boxes_xyxy = _decode_boxes(predicted_offsets = predicted_offsets, priors = priors, variances = variances)\n",
    "\n",
    "    # Calculating the scores from the logits\n",
    "    scores = _score_from_logits(predicted_logits = predicted_logits, scores_thresh = scores_thresh, use_sigmoid = use_sigmoid)\n",
    "\n",
    "    # Check if there is a filter option\n",
    "    if 'min_box_size' in kwargs:\n",
    "       boxes_xyxy, scores, keep_mask = _filter_small_boxes(boxes_xyxy, scores,kwargs['min_box_size'])\n",
    "\n",
    "    if 'pre_nms_top_k' in kwargs:\n",
    "        boxes_xyxy, scores = _pre_nms_top_k(boxes_xyxy, scores, kwargs['pre_nms_top_k'])\n",
    "\n",
    "    # Preparing the inputs for NMS outputs\n",
    "    nms_boxes, nms_scores = _prepare_nms_inputs(boxes_xyxy, scores)\n",
    "\n",
    "    # Run batched NMS\n",
    "    nmsed_boxes,nmsed_scores, nmsed_classes, valid_detections = _run_batched_nms(nms_boxes,nms_scores,iou_thresh, scores_thresh, top_k, max_detections)\n",
    "\n",
    "    if not use_sigmoid:\n",
    "        # Accounting for Softmax probs\n",
    "        nmsed_classes = tf.cast(nmsed_classes,tf.int32)\n",
    "        nmsed_classes = nmsed_classes + 1\n",
    "\n",
    "    # Returning the boxes to image space\n",
    "    if image_meta is not None:\n",
    "        nmsed_boxes = _restore_to_image_space(nmsed_boxes,image_meta['image_height'], image_meta['image_width'])\n",
    "    \n",
    "    return nmsed_boxes,nmsed_scores, nmsed_classes, valid_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93813233-b698-474e-8dd3-7209bb4971ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_loc = tf.constant(\n",
    "    [\n",
    "  [  # batch 0\n",
    "    [ 0.0,  0.0,  0.0,  0.0],   # anchor 0\n",
    "    [ 0.2,  0.0,  0.0,  0.0],   # anchor 1\n",
    "    [ 0.0,  0.0,  0.5,  0.0],   # anchor 2\n",
    "    [ 0.0, -0.2,  0.0, -0.5],   # anchor 3\n",
    "  ]\n",
    "]\n",
    ")\n",
    "\n",
    "pred_logits = tf.constant(\n",
    "    [\n",
    "  [  # batch 0\n",
    "    [0.1,  2.0,  0.0],   # anchor 0\n",
    "    [0.0,  0.5,  3.0],   # anchor 1\n",
    "    [0.5,  1.5, -1.0],   # anchor 2\n",
    "    [0.2, -0.5,  0.0],   # anchor 3\n",
    "  ]\n",
    "]\n",
    ")\n",
    "\n",
    "priors = tf.constant(\n",
    "    [\n",
    "  [0.25, 0.25, 0.2, 0.2],  # anchor 0 (top-left)\n",
    "  [0.75, 0.25, 0.2, 0.2],  # anchor 1 (top-right)\n",
    "  [0.25, 0.75, 0.2, 0.2],  # anchor 2 (bottom-left)\n",
    "  [0.75, 0.75, 0.2, 0.2],  # anchor 3 (bottom-right)\n",
    "]\n",
    ")\n",
    "\n",
    "variances      = tf.constant([0.1, 0.2])\n",
    "score_thresh   = 0.3\n",
    "iou_thresh     = 0.5\n",
    "top_k          = 50           # big enough; not really limiting here\n",
    "max_detections = 3\n",
    "use_sigmoid    = False        # weâ€™re using softmax with background\n",
    "image_meta     = {'image_height': 300, 'image_width': 300}         # keep normalized coords for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4f228ab-e787-457d-b5d4-30bae0cd1ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 3, 4), dtype=float32, numpy=\n",
       " array([[[ 45.     , 196.2    , 105.     , 256.2    ],\n",
       "         [ 45.     ,  45.     , 105.     , 105.     ],\n",
       "         [195.     ,  41.84487, 255.     , 108.15513]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[0.88349205, 0.77826834, 0.68967205]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[2, 1, 1]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([3], dtype=int32)>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_and_nms(pred_loc, pred_logits, priors, variances,score_thresh,iou_thresh,top_k,max_detections,image_meta,use_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc79721b-bea8-4cd4-9b33-a7724f52839c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
