{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f218acee-0e58-40f8-96e3-f40b62ecd9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d44242c-ac4a-4c4b-8d7e-b84448b2d3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 19:24:39.553033: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-29 19:24:39.577497: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-29 19:24:39.585385: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-29 19:24:39.607579: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-29 19:24:40.622894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c42dfef2-ad76-4c94-a85a-62658eea3ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilenetv2ssd.core.config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9e5a365-97e6-45fe-aec1-6a476b18514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "461548d2-b45e-44ec-a1b2-de6a00f035ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilenetv2ssd.models.ssd.ops.loss_ops_tf import multibox_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e194d2c8-4289-4e78-9878-3814db6c1d8b",
   "metadata": {},
   "source": [
    "## Config Files To Test Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbc4f911-e28b-41b1-ad57-515bc0c9bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cfg_path = \"configs/train/default.yaml\"\n",
    "model_cfg_path = \"configs/model/mobilenetv2_ssd_voc.yaml\"\n",
    "data_cfg_path = \"configs/data/voc_224.yaml\"\n",
    "eval_cfg_path = \"configs/eval/default.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be5407ed-6d4c-43be-8db7-4bc9a82edf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(main_cfg_path,model_cfg_path,data_cfg_path,eval_cfg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f135767-f648-43ab-a9a9-cf22baf51098",
   "metadata": {},
   "source": [
    "## Helper Functions For Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70687ead-b374-4bd6-8998-56aae80df0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_information_from_train_config(config : dict[str, Any]):\n",
    "    train_config = config['train']\n",
    "    model_config = config['model']\n",
    "    loss_config = train_config.get(\"loss\",{})\n",
    "    loss_config = {\n",
    "        \"cls_loss_type\": loss_config.get(\"cls_loss_type\",\"ce_softmax\"),\n",
    "        \"reg_loss_type\": loss_config.get(\"reg_loss_type\",\"smooth_l1\"),\n",
    "        \"smooth_l1_beta\": loss_config.get(\"smooth_l1_beta\",1.0),\n",
    "        \"bbox_norm\": loss_config.get(\"bbox_norm\",\"none\"),\n",
    "        \"from_logits\": loss_config.get(\"from_logits\",False),\n",
    "        \"ignore_index\": loss_config.get(\"ignore_index\",-1),\n",
    "        \"use_sigmoid\": loss_config.get(\"use_sigmoid\",False),\n",
    "        \"classification_weights\": loss_config.get(\"cls_weight\",1.0),\n",
    "        \"localization_weights\": loss_config.get(\"reg_weight\",1.0),\n",
    "        \"normalization_denom\": loss_config.get(\"normalization\",{}).get(\"type\",\"num_pos\"),\n",
    "        \"num_classes\": model_config.get(\"num_classes\",1),\n",
    "        \"reduction\": loss_config.get(\"reduction\",\"sum\")\n",
    "    }\n",
    "\n",
    "    return loss_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e799cc7-83cd-45e2-afa1-f6cbc149db2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cls_loss_type': 'softmax_ce',\n",
       " 'reg_loss_type': 'smooth_l1',\n",
       " 'smooth_l1_beta': 1.0,\n",
       " 'bbox_norm': 'none',\n",
       " 'from_logits': True,\n",
       " 'ignore_index': -1,\n",
       " 'use_sigmoid': False,\n",
       " 'classification_weights': 1.0,\n",
       " 'localization_weights': 1.0,\n",
       " 'normalization_denom': 'num_pos',\n",
       " 'num_classes': 21,\n",
       " 'reduction': 'sum'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_extract_information_from_train_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ea3ef-eb92-4332-a749-7e489fe73b58",
   "metadata": {},
   "source": [
    "## Orchestration Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f2e1f89-70bd-4ada-82da-1abfcb55278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_final_loss(config: dict[str,Any], predicted_offsets: tf.Tensor, predicted_logits: tf.Tensor, localization_targets: tf.Tensor, classification_targets: tf.Tensor, positive_mask: tf.Tensor, negative_mask: tf.Tensor):\n",
    "    # This is the function that calculates the multibox loss for the model\n",
    "    # Steps:\n",
    "    # 1. Get values from the config.\n",
    "    # 2. Calculate the multibox loss\n",
    "\n",
    "    loss_config = _extract_information_from_train_config(config)\n",
    "    # loss_dict = tf.map_fn(lambda inputs: multibox_loss(predicted_offsets = inputs[0], predicted_logits = inputs[1], target_offsets = inputs[2], target_labels = inputs[3], positive_mask = inputs[4], negative_mask = inputs[5], localization_weight = loss_config[\"localization_weights\"], classification_weight = loss_config[\"classification_weights\"], beta = loss_config[\"smooth_l1_beta\"], cls_loss_type = loss_config[\"cls_loss_type\"],loc_loss_type = loss_config[\"reg_loss_type\"], normalize_denom = loss_config[\"normalization_denom\"], reduction = loss_config['reduction']),\n",
    "    #                       elems = (predicted_offsets,predicted_logits,localization_targets,classification_targets,positive_mask,negative_mask),\n",
    "    #                       fn_output_signature = {\n",
    "    #                           \"total_loss\": tf.TensorSpec(shape=(), dtype=tf.float32),\n",
    "    #                           \"loc_loss\": tf.TensorSpec(shape=(), dtype=tf.float32),\n",
    "    #                           \"cls_loss\": tf.TensorSpec(shape=(), dtype=tf.float32),\n",
    "    #                           \"num_pos\": tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "    #                           \"num_negative\": tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "    #                       }\n",
    "    #                      )\n",
    "\n",
    "    loss_dict = multibox_loss(predicted_offsets = predicted_offsets, predicted_logits = predicted_logits, target_offsets = localization_targets, target_labels = classification_targets, positive_mask = positive_mask, negative_mask = negative_mask, localization_weight = loss_config[\"localization_weights\"], classification_weight = loss_config[\"classification_weights\"], beta = loss_config[\"smooth_l1_beta\"], cls_loss_type = loss_config[\"cls_loss_type\"],loc_loss_type = loss_config[\"reg_loss_type\"], normalize_denom = loss_config[\"normalization_denom\"], reduction = loss_config['reduction'])\n",
    "\n",
    "    return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da92ea7b-b45b-47c4-9571-0ffa3bf32e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_offsets = tf.constant([\n",
    "    # Image 0 priors 0..4\n",
    "    [\n",
    "        [0.10,  0.05,  0.02, -0.01],  # prior 0\n",
    "        [0.00, -0.03,  0.01,  0.04],  # prior 1\n",
    "        [0.20, -0.10,  0.05,  0.02],  # prior 2\n",
    "        [-0.05, 0.02,  0.01,  0.00],  # prior 3\n",
    "        [0.03,  0.00, -0.02,  0.01],  # prior 4\n",
    "    ],\n",
    "    # Image 1 priors 0..4\n",
    "    [\n",
    "        [0.02,  0.01,  0.00, -0.01],  # prior 0\n",
    "        [-0.01, 0.00,  0.03,  0.02],  # prior 1\n",
    "        [0.15, -0.05,  0.04,  0.01],  # prior 2\n",
    "        [0.00, -0.02,  0.00,  0.03],  # prior 3\n",
    "        [-0.03, 0.01, -0.01,  0.00],  # prior 4\n",
    "    ],\n",
    "], dtype=tf.float32)\n",
    "\n",
    "target_offsets = tf.constant([\n",
    "    # Image 0\n",
    "    [\n",
    "        [0.12,  0.04,  0.01, -0.02],  # prior 0 (positive)\n",
    "        [0.00,  0.00,  0.00,  0.00],  # prior 1 (neg)\n",
    "        [0.18, -0.08,  0.06,  0.01],  # prior 2 (positive)\n",
    "        [0.00,  0.00,  0.00,  0.00],  # prior 3 (neg)\n",
    "        [0.00,  0.00,  0.00,  0.00],  # prior 4 (neg)\n",
    "    ],\n",
    "    # Image 1\n",
    "    [\n",
    "        [0.00,  0.00,  0.00,  0.00],  # prior 0 (neg)\n",
    "        [0.00,  0.00,  0.00,  0.00],  # prior 1 (neg)\n",
    "        [0.14, -0.06,  0.05,  0.02],  # prior 2 (positive)\n",
    "        [0.00,  0.00,  0.00,  0.00],  # prior 3 (neg)\n",
    "        [0.00,  0.00,  0.00,  0.00],  # prior 4 (neg)\n",
    "    ],\n",
    "], dtype=tf.float32)\n",
    "\n",
    "predicted_logits = tf.constant([\n",
    "    # Image 0\n",
    "    [\n",
    "        [ -1.0,  0.5,  1.2, -0.3],  # prior 0\n",
    "        [  2.0, -1.0, -0.5, -0.2],  # prior 1\n",
    "        [ -2.0,  1.5,  0.8,  0.0],  # prior 2\n",
    "        [  1.0, -0.5, -0.2, -0.1],  # prior 3\n",
    "        [  1.5, -0.8, -0.3, -0.4],  # prior 4\n",
    "    ],\n",
    "    # Image 1\n",
    "    [\n",
    "        [  2.2, -0.7, -0.4, -0.3],  # prior 0\n",
    "        [  1.8, -0.6, -0.3, -0.5],  # prior 1\n",
    "        [ -1.5,  1.0,  0.9, -0.2],  # prior 2\n",
    "        [  2.0, -1.0, -0.5, -0.3],  # prior 3\n",
    "        [  1.7, -0.9, -0.4, -0.6],  # prior 4\n",
    "    ],\n",
    "], dtype=tf.float32)\n",
    "\n",
    "target_labels = tf.constant([\n",
    "    # Image 0 priors 0..4\n",
    "    [2, 0, 1, 0, 0],\n",
    "    # Image 1 priors 0..4\n",
    "    [0, 0, 3, 0, 0],\n",
    "], dtype=tf.int32)\n",
    "\n",
    "positive_mask = tf.constant([\n",
    "    # Image 0: priors 0 and 2 are positive\n",
    "    [ True, False,  True, False, False],\n",
    "    # Image 1: prior 2 is positive\n",
    "    [False, False,  True, False, False],\n",
    "], dtype=tf.bool)\n",
    "\n",
    "negative_mask = tf.constant([\n",
    "    # Image 0: priors 1, 3, 4 selected as negatives\n",
    "    [False,  True, False,  True,  True],\n",
    "    # Image 1: priors 0, 1, 3, 4 selected as negatives\n",
    "    [ True,  True, False,  True,  True],\n",
    "], dtype=tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bafb0da1-e780-4226-b732-c04a53127dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_loss': <tf.Tensor: shape=(), dtype=float32, numpy=1.7698979>,\n",
       " 'loc_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.00035>,\n",
       " 'cls_loss': <tf.Tensor: shape=(), dtype=float32, numpy=1.7695479>,\n",
       " 'num_pos': <tf.Tensor: shape=(), dtype=int32, numpy=3>,\n",
       " 'num_negative': <tf.Tensor: shape=(), dtype=int32, numpy=7>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_final_loss(config, predicted_offsets = predicted_offsets , predicted_logits = predicted_logits , localization_targets = target_offsets, classification_targets = target_labels, positive_mask = positive_mask, negative_mask = negative_mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3bfa5-b021-42fe-8ea8-d47e935d96c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
