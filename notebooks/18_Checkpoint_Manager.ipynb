{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28441165-ef13-4a8b-b53b-37a6646e888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7217d75-10b8-4dcf-8c4a-a8a91933f56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-26 00:41:48.208212: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-26 00:41:48.225644: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-26 00:41:48.231227: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-26 00:41:48.244102: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-26 00:41:49.193963: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import tensorflow as tf\n",
    "from typing import Any, Optional\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import time\n",
    "import json\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df272e45-8e87-4a22-a976-5f05ebff8fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilenetv2ssd.core.config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1774f9f-293c-42a3-9df8-d49c214418de",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cfg_path = \"configs/train/default.yaml\"\n",
    "model_cfg_path = \"configs/model/mobilenetv2_ssd_voc.yaml\"\n",
    "data_cfg_path = \"configs/data/voc_224.yaml\"\n",
    "eval_cfg_path = \"configs/eval/default.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e48af1d7-f69a-42f1-b177-6325876a5f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(main_cfg_path,model_cfg_path,data_cfg_path,eval_cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07721aed-afea-4674-b5e3-b92e0961c2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dir': '/mnt/d/dev/MobileNetV2-SSD/checkpoints',\n",
       " 'keep_last_k': 5,\n",
       " 'save_every_steps': 500,\n",
       " 'save_every_epochs': 1,\n",
       " 'save_last': True,\n",
       " 'save_best': True,\n",
       " 'monitor': 'val_map',\n",
       " 'mode': 'max'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['checkpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a2a6e46-8569-4f87-8c41-86b0f642c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckpointManager:\n",
    "    def __init__(self, checkpoint_config: dict[str,Any], model: tf.keras.Model, optimizer: tf.keras.optimizers.Optimizer, ema: Optional[Any], is_main_node: bool = True):\n",
    "        self._model = model\n",
    "        self._optimizer = optimizer\n",
    "        \n",
    "        self._checkpoint_directory = Path(checkpoint_config['dir'])\n",
    "        self._checkpoint_directory.mkdir(parents = True, exist_ok = True)\n",
    "        \n",
    "        self._keep_last_k = checkpoint_config.get('keep_last_k', 5)\n",
    "        \n",
    "        self._save_every_steps = checkpoint_config.get('save_every_steps', None)\n",
    "        if self._save_every_steps is not None and self._save_every_steps <= 0:\n",
    "            raise ValueError(\"The value has to be greater than 0\")\n",
    "        \n",
    "        self._save_every_epochs = checkpoint_config.get('save_every_epochs', 1)\n",
    "        self._save_last = checkpoint_config.get('save_last', True)\n",
    "        self._save_best = checkpoint_config.get('save_best', True)\n",
    "        self._monitor = checkpoint_config.get('monitor', \"val_map\")\n",
    "        self._mode = checkpoint_config.get('mode', \"max\")\n",
    "\n",
    "        if self._mode not in {\"max\",\"min\"}:\n",
    "            raise ValueError(\"The value for the mode is wrong and should be either 'max' or 'min'\")\n",
    "        \n",
    "        self._ema = ema\n",
    "\n",
    "        # Saving the main status (rank = 0) to stop potential I/O problems when using DDP\n",
    "        self._is_main = is_main_node\n",
    "\n",
    "        # Creating the variables to use\n",
    "        self._epoch_var = tf.Variable(0, dtype = tf.int64, trainable = False)\n",
    "        self._global_step_var = tf.Variable(0, dtype = tf.int64, trainable = False)\n",
    "        self._best_epoch_var = tf.Variable(-1, dtype = tf.int64, trainable = False)\n",
    "        self._best_metric_var = tf.Variable(float(\"-inf\"), dtype = tf.float32, trainable = False) if self._mode == \"max\" else tf.Variable(float(\"inf\"), dtype = tf.float32, trainable = False)\n",
    "\n",
    "        # Building the checkpoint bundle for the manager to store\n",
    "        checkpoint_dict = {\n",
    "            'model': self._model,\n",
    "            'epoch': self._epoch_var,\n",
    "            'global_step': self._global_step_var,\n",
    "            'best_epoch': self._best_epoch_var,\n",
    "            'best_metric': self._best_metric_var\n",
    "        }\n",
    "\n",
    "        if self._ema is not None:\n",
    "            checkpoint_dict['ema'] = self._ema\n",
    "        \n",
    "        self._checkpoint = tf.train.Checkpoint(**checkpoint_dict)\n",
    "\n",
    "        # Ensuring the /last subdirectory is creating in the checkpoint \n",
    "        self._last_directory = self._checkpoint_directory / \"last\"\n",
    "        self._last_directory.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "        # Now creating the two checkpoint managers that will be used (last & best)\n",
    "        self._last_manager = tf.train.CheckpointManager(checkpoint = self._checkpoint, directory = str( self._last_directory), max_to_keep = self._keep_last_k)\n",
    "        self._best_manager = None\n",
    "\n",
    "        # This manager is used when there is a metric increase.\n",
    "        if self._save_best:\n",
    "            # There is a save best manager that is used\n",
    "            self._best_directory = self._checkpoint_directory / \"best\"\n",
    "            self._best_directory.mkdir(parents = True, exist_ok = True)\n",
    "            self._best_manager = tf.train.CheckpointManager(checkpoint = self._checkpoint, directory = str(self._best_directory), max_to_keep = 1)\n",
    "        \n",
    "    def restore_latest(self):\n",
    "        # Accessing the last manager and its parts\n",
    "        latest_path = self._last_manager.latest_checkpoint\n",
    "\n",
    "        if latest_path is None:\n",
    "            latest_dir = Path(self._last_manager.directory)\n",
    "            index_files = list(latest_dir.glob(\"ckpt-*.index\"))\n",
    "            if index_files:\n",
    "                newest = max(index_files, key = self._select_checkpoint)\n",
    "                latest_path = str(newest.with_suffix(\"\"))\n",
    "\n",
    "        # Checking if the path is None\n",
    "        if latest_path is None:\n",
    "            return {'restored': False, 'epoch': 0, 'global_step': 0, 'best_metric': float(\"-inf\") if self._mode == \"max\" else float(\"inf\") , 'best_epoch': -1}\n",
    "\n",
    "        # There is a checkpoint and now needs to be loaded\n",
    "        self._checkpoint.restore(latest_path).expect_partial()\n",
    "\n",
    "        # Now getting the values to return to the training loop to resume correctly\n",
    "        epoch = int(self._epoch_var.numpy())\n",
    "        global_step = int(self._global_step_var.numpy())\n",
    "        best_metric = float(self._best_metric_var.numpy())\n",
    "        best_epoch = int(self._best_epoch_var.numpy())\n",
    "\n",
    "        return {'restored': True, 'epoch': epoch, 'global_step': global_step, 'best_metric': best_metric , 'best_epoch': best_epoch}\n",
    "\n",
    "    def restore_best(self):\n",
    "        # Check if the best manager is even initialized since it can be disabled\n",
    "        if self._best_manager is None:\n",
    "            return {'restored': False, 'epoch': 0, 'global_step': 0, 'best_metric': float(\"-inf\") if self._mode == \"max\" else float(\"inf\") , 'best_epoch': -1}\n",
    "\n",
    "        # Now check if the checkpoint exists\n",
    "        best_path = self._best_manager.latest_checkpoint\n",
    "\n",
    "        if best_path is None:\n",
    "            best_dir = Path(self._best_manager.directory)\n",
    "            index_files = list(best_dir.glob(\"ckpt-*.index\"))\n",
    "            if index_files:\n",
    "                newest = max(index_files, key = self._select_checkpoint)\n",
    "                best_path = str(newest.with_suffix(\"\"))\n",
    "                \n",
    "        # Check if the path exists\n",
    "        if best_path is None:\n",
    "            return {'restored': False, 'epoch': 0, 'global_step': 0, 'best_metric': float(\"-inf\") if self._mode == \"max\" else float(\"inf\") , 'best_epoch': -1}\n",
    "\n",
    "        # The path exists and now needs to be restored\n",
    "        self._checkpoint.restore(best_path).expect_partial()\n",
    "\n",
    "        # Now getting the values to return to the training loop to resume correctly\n",
    "        epoch = int(self._epoch_var.numpy())\n",
    "        global_step = int(self._global_step_var.numpy())\n",
    "        best_metric = float(self._best_metric_var.numpy())\n",
    "        best_epoch = int(self._best_epoch_var.numpy())\n",
    "\n",
    "        return {'restored': True, 'epoch': epoch, 'global_step': global_step, 'best_metric': best_metric , 'best_epoch': best_epoch}\n",
    "\n",
    "    def save_last(self, epoch: int, global_step: int):\n",
    "\n",
    "        if not self._is_main:\n",
    "            return None\n",
    "\n",
    "        # Now saving the variables\n",
    "        self._epoch_var.assign(epoch)\n",
    "        self._global_step_var.assign(global_step)\n",
    "\n",
    "        # Path create checkpoint file name\n",
    "        save_path = self._last_manager.save(checkpoint_number = global_step)\n",
    "\n",
    "        return save_path\n",
    "        \n",
    "    def save_best(self, epoch: int, global_step: int, metric: float):\n",
    "        if not self._is_main:\n",
    "            return {'is_best': False, 'path': None}\n",
    "        \n",
    "        if not self._save_best or self._best_manager is None:\n",
    "            return {'is_best': False, 'path': None}\n",
    "\n",
    "        # Now checking if the metric is less than or more than the value\n",
    "        if self._compare_metrics(metric):\n",
    "            \n",
    "            # Assign the metric and the epoch to track the best\n",
    "            self._best_metric_var.assign(metric)\n",
    "            self._best_epoch_var.assign(epoch)\n",
    "            self._epoch_var.assign(epoch)\n",
    "            self._global_step_var.assign(global_step)\n",
    "\n",
    "            # Save the checkpoint\n",
    "            best_path = self._best_manager.save(checkpoint_number = global_step)\n",
    "\n",
    "            return {'is_best': True, 'path': best_path}\n",
    "\n",
    "        return {'is_best': False, 'path': None}\n",
    "\n",
    "    def _compare_metrics(self, metric: float):\n",
    "\n",
    "        # Now comparing the metric\n",
    "        if self._mode == \"max\":\n",
    "            return metric > float(self._best_metric_var.numpy())\n",
    "        else:\n",
    "            return metric < float(self._best_metric_var.numpy())\n",
    "\n",
    "    def _select_checkpoint(self,p: Path):\n",
    "        # \"ckpt-123.index\" -> 123\n",
    "        stem = p.name.split(\".\")[0]      # \"ckpt-123\"\n",
    "        return int(stem.split(\"-\")[1])   # 123\n",
    "\n",
    "    def should_save_step(self, global_step: int):\n",
    "        # Now checking if the conditions for the steps are not violated\n",
    "        if not self._save_last:\n",
    "            return False\n",
    "\n",
    "        # Checking if the checkpoint needs to saved every k steps\n",
    "        if self._save_every_steps is None:\n",
    "            return False\n",
    "\n",
    "        # Now checking if the step is exactly the interval to save the checkpoint on\n",
    "        if global_step % self._save_every_steps == 0:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def should_save_epoch(self,epoch: int):\n",
    "        # Now checking if the conditions for the epochs are not violated\n",
    "        if not self._save_last:\n",
    "            return False\n",
    "\n",
    "        # Default is to save every epoch so there is no need for the second condition\n",
    "        if (epoch + 1) % self._save_every_epochs == 0:\n",
    "            return True\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f3c22-32a1-479e-a749-e7ba875ee8f8",
   "metadata": {},
   "source": [
    "## Testing the Checkpoint Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e32d4b6f-da8c-4154-bb84-7e7ebf0a5ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1766727710.396967    3054 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1766727710.474114    3054 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1766727710.474178    3054 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1766727710.475750    3054 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1766727710.475822    3054 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1766727710.475858    3054 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1766727710.648180    3054 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1766727710.648294    3054 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-26 00:41:50.648309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-12-26 00:41:50.648334: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:198] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1766727710.648705    3054 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-26 00:41:50.648747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_best returns:\n",
      " r1 = {'is_best': True, 'path': '/tmp/tmpfrpuiuo7/checkpoints/best/ckpt-0'}\n",
      " r2 = {'is_best': False, 'path': None}\n",
      " r3 = {'is_best': True, 'path': '/tmp/tmpfrpuiuo7/checkpoints/best/ckpt-2'}\n",
      "\n",
      "latest_checkpoint (writer ckpt): /tmp/tmpfrpuiuo7/checkpoints/best/ckpt-2\n",
      "latest_checkpoint (stale ckpt2): None\n",
      "\n",
      "restore_best() state: {'restored': True, 'epoch': 2, 'global_step': 2, 'best_metric': 0.30000001192092896, 'best_epoch': 2}\n"
     ]
    }
   ],
   "source": [
    "run_dir = Path(tempfile.mkdtemp()) / \"checkpoints\"\n",
    "cfg = {\n",
    "    \"dir\": str(run_dir),\n",
    "    \"keep_last_k\": 2,\n",
    "    \"save_last\": True,\n",
    "    \"save_best\": True,\n",
    "    \"save_every_steps\": None,\n",
    "    \"save_every_epochs\": 1,\n",
    "    \"monitor\": \"val_map\",\n",
    "    \"mode\": \"max\",\n",
    "}\n",
    "\n",
    "# 2) Objects for ckpt (writer)\n",
    "model = tf.keras.Sequential([tf.keras.layers.Input((4,)), tf.keras.layers.Dense(1)])\n",
    "opt = tf.keras.optimizers.Adam(1e-3)\n",
    "\n",
    "_ = model(tf.zeros([1,4]))  # build vars\n",
    "\n",
    "ckpt = CheckpointManager(cfg, model, opt, ema=None, is_main_node=True)\n",
    "\n",
    "# 3) Objects for ckpt2 (reader) -- created BEFORE best exists (this is the stale case)\n",
    "model2 = tf.keras.Sequential([tf.keras.layers.Input((4,)), tf.keras.layers.Dense(1)])\n",
    "opt2 = tf.keras.optimizers.Adam(1e-3)\n",
    "_ = model2(tf.zeros([1,4]))  # build vars\n",
    "\n",
    "ckpt2 = CheckpointManager(cfg, model2, opt2, ema=None, is_main_node=True)\n",
    "\n",
    "# 4) Save a couple best checkpoints (writer only)\n",
    "r1 = ckpt.save_best(epoch=0, global_step=0, metric=0.2)\n",
    "r2 = ckpt.save_best(epoch=1, global_step=1, metric=0.1)  # worse -> should not save\n",
    "r3 = ckpt.save_best(epoch=2, global_step=2, metric=0.3)  # better -> should save\n",
    "\n",
    "print(\"save_best returns:\")\n",
    "print(\" r1 =\", r1)\n",
    "print(\" r2 =\", r2)\n",
    "print(\" r3 =\", r3)\n",
    "\n",
    "# 5) Debug: show stale latest_checkpoint state (expected ckpt sees it, ckpt2 might not)\n",
    "print(\"\\nlatest_checkpoint (writer ckpt):\", ckpt._best_manager.latest_checkpoint)\n",
    "print(\"latest_checkpoint (stale ckpt2):\", ckpt2._best_manager.latest_checkpoint)\n",
    "\n",
    "# 6) Restore best using stale ckpt2 (this is what failed before)\n",
    "state_best = ckpt2.restore_best()\n",
    "print(\"\\nrestore_best() state:\", state_best)\n",
    "\n",
    "# 7) Assertions\n",
    "assert r2[\"is_best\"] is False\n",
    "assert r3[\"is_best\"] is True\n",
    "\n",
    "assert state_best[\"restored\"] is True\n",
    "assert abs(state_best[\"best_metric\"] - 0.3) < 1e-6\n",
    "assert state_best[\"best_epoch\"] == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc761b89-5fcd-4945-b6b9-f4103011cf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker save_last returned: None\n",
      "worker save_best returned: {'is_best': False, 'path': None}\n",
      "last_dir files: []\n",
      "best_dir files: []\n"
     ]
    }
   ],
   "source": [
    "run_dir = Path(tempfile.mkdtemp()) / \"checkpoints\"\n",
    "cfg = {\"dir\": str(run_dir), \"keep_last_k\": 2, \"save_last\": True, \"save_best\": True,\n",
    "       \"save_every_steps\": None, \"save_every_epochs\": 1, \"monitor\": \"val_map\", \"mode\": \"max\"}\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Input((4,)), tf.keras.layers.Dense(1)])\n",
    "opt = tf.keras.optimizers.Adam(1e-3)\n",
    "_ = model(tf.zeros([1,4]))\n",
    "\n",
    "ckpt_worker = CheckpointManager(cfg, model, opt, ema=None, is_main_node=False)\n",
    "\n",
    "p_last = ckpt_worker.save_last(epoch=0, global_step=10)\n",
    "p_best = ckpt_worker.save_best(epoch=0, global_step=10, metric=0.9)\n",
    "\n",
    "print(\"worker save_last returned:\", p_last)\n",
    "print(\"worker save_best returned:\", p_best)\n",
    "\n",
    "# Expectations:\n",
    "assert p_last is None\n",
    "assert p_best[\"is_best\"] is False and p_best[\"path\"] is None\n",
    "\n",
    "# Also expect no checkpoint files exist\n",
    "last_dir = Path(cfg[\"dir\"]) / \"last\"\n",
    "best_dir = Path(cfg[\"dir\"]) / \"best\"\n",
    "print(\"last_dir files:\", list(last_dir.glob(\"*\")))\n",
    "print(\"best_dir files:\", list(best_dir.glob(\"*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a6dd76b-bda1-42a9-9fc6-1bb0c45b2ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main saved last: /tmp/tmpfi6xs4ti/checkpoints/last/ckpt-777\n",
      "main saved best: {'is_best': True, 'path': '/tmp/tmpfi6xs4ti/checkpoints/best/ckpt-777'}\n",
      "worker restore_latest: {'restored': True, 'epoch': 5, 'global_step': 777, 'best_metric': -inf, 'best_epoch': -1}\n",
      "worker restore_best: {'restored': True, 'epoch': 5, 'global_step': 777, 'best_metric': 0.41999998688697815, 'best_epoch': 5}\n"
     ]
    }
   ],
   "source": [
    "modelM = tf.keras.Sequential([tf.keras.layers.Input((4,)), tf.keras.layers.Dense(1)])\n",
    "optM = tf.keras.optimizers.Adam(1e-3)\n",
    "_ = modelM(tf.zeros([1,4]))\n",
    "ckpt_main = CheckpointManager(cfg, modelM, optM, ema=None, is_main_node=True)\n",
    "\n",
    "p = ckpt_main.save_last(epoch=5, global_step=777)\n",
    "b = ckpt_main.save_best(epoch=5, global_step=777, metric=0.42)\n",
    "\n",
    "print(\"main saved last:\", p)\n",
    "print(\"main saved best:\", b)\n",
    "\n",
    "# Reader (worker rank) - should NOT write, but CAN restore\n",
    "modelW = tf.keras.Sequential([tf.keras.layers.Input((4,)), tf.keras.layers.Dense(1)])\n",
    "optW = tf.keras.optimizers.Adam(1e-3)\n",
    "_ = modelW(tf.zeros([1,4]))\n",
    "ckpt_worker = CheckpointManager(cfg, modelW, optW, ema=None, is_main_node=False)\n",
    "\n",
    "state_last = ckpt_worker.restore_latest()\n",
    "state_best = ckpt_worker.restore_best()\n",
    "\n",
    "print(\"worker restore_latest:\", state_last)\n",
    "print(\"worker restore_best:\", state_best)\n",
    "\n",
    "# Expectations:\n",
    "assert state_last[\"restored\"] is True\n",
    "assert state_last[\"epoch\"] == 5\n",
    "assert state_last[\"global_step\"] == 777\n",
    "\n",
    "assert state_best[\"restored\"] is True\n",
    "assert abs(state_best[\"best_metric\"] - 0.42) < 1e-6\n",
    "assert state_best[\"best_epoch\"] == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1139bb64-294f-4412-804e-180f72888a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'voc',\n",
       " 'root': '/mnt/d/dev/MobileNetV2-SSD/datasets/VOCdevkit',\n",
       " 'train_split': 'trainval',\n",
       " 'val_split': 'test',\n",
       " 'input_size': [224, 224],\n",
       " 'num_workers': 4,\n",
       " 'shuffle_buffer': 1000,\n",
       " 'prefetch_batches': 2,\n",
       " 'augment': {'random_flip': True,\n",
       "  'random_flip_prob': 0.5,\n",
       "  'random_crop': True,\n",
       "  'min_crop_iou_choices': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
       "  'min_crop_scale': 0.3,\n",
       "  'max_crop_scale': 1.0,\n",
       "  'photometric_distort': True,\n",
       "  'photometric_distort_prob': 0.5},\n",
       " 'normalization': {'mean': [0.485, 0.456, 0.406],\n",
       "  'std': [0.229, 0.224, 0.225]},\n",
       " 'classes_file': '/mnt/d/dev/MobileNetV2-SSD/configs/data/voc_classes.txt'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "885ad9cb-c1f6-4fa5-941d-b8e2f89a7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_checkpoint_directory_fingerprint(config: dict[str,Any]):\n",
    "    model_config = config['model']\n",
    "    dataset_config = config['data']\n",
    "    train_config = config['train']\n",
    "\n",
    "    fingerprint_config = {\n",
    "        'model_backbone': model_config.get('backbone',''),\n",
    "        'num_classes': model_config.get('num_classes',0),\n",
    "        'priors': model_config.get('priors',{}),\n",
    "        'dataset_name': dataset_config.get('dataset_name', ''),\n",
    "        'dataset_augmentation': dataset_config.get('augment', {}),\n",
    "        'dataset_normalization': dataset_config.get('normalization', {}),\n",
    "        'training_batch_size': train_config.get('batch_size', 0),\n",
    "        'training_epochs': train_config.get('epochs', 0),\n",
    "        'training_optimizer_name': train_config['optimizer'].get('name', ''),\n",
    "        'training_optimizer_lr': train_config['optimizer'].get('lr', 0.0),\n",
    "        'training_optimizer_weight_decay': train_config['optimizer'].get('weight_decay', 0.0),\n",
    "        'training_scheduler_params':train_config.get('scheduler',{})\n",
    "    }\n",
    "\n",
    "    config_json = json.dumps(fingerprint_config,sort_keys = True, separators=(\",\",\":\"))\n",
    "    hash_object = hashlib.sha256(config_json.encode('utf-8'))\n",
    "    hex_digest = hash_object.hexdigest()[:10]\n",
    "\n",
    "    file_slug = f\"{model_config['name']}_{dataset_config['dataset_name']}_img{dataset_config['input_size'][0]}_bs{fingerprint_config['training_batch_size']}_lr{fingerprint_config['training_optimizer_lr']:.2e}_{train_config['scheduler']['name']}\"\n",
    "    file_name = f\"{file_slug}_{hex_digest}\"\n",
    "\n",
    "    root_dir =  config['checkpoint']['dir']\n",
    "    run_dir = Path(root_dir) / file_name\n",
    "    \n",
    "    return {\n",
    "        'dir': str(run_dir),\n",
    "        'keep_last_k': config['checkpoint'].get('keep_last_k', 1),\n",
    "        'save_every_steps': config['checkpoint'].get('save_every_steps', 200),\n",
    "        'save_every_epochs': config['checkpoint'].get('save_every_epochs', 1),\n",
    "        'save_last': config['checkpoint'].get('save_last', True),\n",
    "        'save_best': config['checkpoint'].get('save_best', True),\n",
    "        'monitor': config['checkpoint'].get('monitor', 'val_map'),\n",
    "        'mode': config['checkpoint'].get('mode', 'max')\n",
    "    }\n",
    "\n",
    "def build_checkpoint_manager(config: dict[str,Any], model: tf.keras.Model, optimizer: tf.keras.optimizers.Optimizer, ema: Optional[Any], is_main_node: bool =True):\n",
    "    checkpoint_config = _create_checkpoint_directory_fingerprint(config)\n",
    "\n",
    "    checkpoint_manager = CheckpointManager(checkpoint_config, model, optimizer, ema= ema, is_main_node= is_main_node)\n",
    "\n",
    "    return checkpoint_manager\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d161ebb6-63ea-4c2b-8016-144fcb632a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CheckpointManager at 0x7cbc87fe4340>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_checkpoint_manager(config,modelM, optM, None, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865e5c2e-aaab-4f99-9a7d-7fb5ff0aeca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
