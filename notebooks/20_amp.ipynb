{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99fb3a5b-5bb6-4924-be04-45444f6bed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca4d129c-ecc0-4025-9e4a-92a79350b0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-19 23:05:40.904226: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-19 23:05:40.925176: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-19 23:05:40.931229: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-19 23:05:40.946804: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-19 23:05:41.946772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from typing import Any, Optional\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75742fde-7dd1-4f94-a45f-c50b79e94d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilenetv2ssd.core.config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b14a7f6-1da0-4228-97df-f29e696aa352",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cfg_path = \"configs/train/default.yaml\"\n",
    "model_cfg_path = \"configs/model/mobilenetv2_ssd_voc.yaml\"\n",
    "data_cfg_path = \"configs/data/voc_224.yaml\"\n",
    "eval_cfg_path = \"configs/eval/default.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b467f2-9425-446f-ad83-71e105f79fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(main_cfg_path,model_cfg_path,data_cfg_path,eval_cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "171adee7-9370-490f-9792-e854ed8e69b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enabled': True,\n",
       " 'policy': 'mixed_float16',\n",
       " 'loss_scale': 'dynamic',\n",
       " 'clip_unscaled_grads': True,\n",
       " 'force_fp32': ['loss_reduction', 'box_encode_decode', 'iou', 'nms']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['train']['amp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7308eed2-28b2-4650-953f-f96155480efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrecisionConfig:\n",
    "    def __init__(self, forced_precision: set[str]):\n",
    "        self._forced_precision_fields = forced_precision\n",
    "\n",
    "    def is_force_fp32_enabled(self, tag: str):\n",
    "        if tag in self._forced_precision_fields:\n",
    "            return True\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efd4dbc2-ebf1-4a8e-bdcf-1c27a28b2224",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMPContext:\n",
    "    def __init__(self, config: dict[str, Any], optimizer: tf.keras.optimizers.Optimizer):\n",
    "        self._enabled = config['enabled']\n",
    "        self._policy = config['policy']\n",
    "        self._loss_scale : str | float = config['loss_scale']\n",
    "        self._clip_unscaled_grads = config['clip_unscaled_grads']\n",
    "        self._force_fp32 = set(config['force_fp32'])\n",
    "        self._policy_set = False\n",
    "        self._base_optimizer = optimizer\n",
    "        self.optimizer = optimizer # Use this optimzer only to handle the mixed precision\n",
    "\n",
    "    def setup_policy(self):\n",
    "\n",
    "        # Guarding against different strings\n",
    "        if self._policy not in {'mixed_float16', 'mixed_bfloat16', 'float32'}:\n",
    "            raise ValueError(f\"AMP policy name is not valid, error value: {self._policy}, allowed values: {['mixed_float16', 'mixed_bfloat16', 'float32']}\")\n",
    "        \n",
    "        # Check if the policy is set\n",
    "        if self._policy_set:\n",
    "            return\n",
    "        \n",
    "        # Need to check if amp is enabled or not\n",
    "        if self._enabled:\n",
    "            # Enable the global precision policy\n",
    "            policy = tf.keras.mixed_precision.Policy(self._policy)\n",
    "            tf.keras.mixed_precision.set_global_policy(policy)\n",
    "            self._policy_set = True\n",
    "            return\n",
    "        else:\n",
    "            # Setting it to float32 policy even though it is default behaviour\n",
    "            policy = tf.keras.mixed_precision.Policy(\"float32\")\n",
    "            tf.keras.mixed_precision.set_global_policy(policy)\n",
    "            self._policy_set = True\n",
    "            return\n",
    "\n",
    "    def wrap_optimizer(self):\n",
    "        # Need to check if AMP is even on\n",
    "        if not self._enabled:\n",
    "            # AMP is off so return the optimzer with the base version\n",
    "            self.optimizer = self._base_optimizer\n",
    "            return self.optimizer\n",
    "\n",
    "        # Now worrying about the loss scaling mode since AMP is on\n",
    "        if self._loss_scale == \"dynamic\":\n",
    "            \n",
    "            # Wrapping the optimizer in the loss scale mode to allow for mixed precision\n",
    "            self.optimizer = tf.keras.mixed_precision.LossScaleOptimizer(self._base_optimizer)\n",
    "\n",
    "        else:\n",
    "            # It is a number and needs to be positive\n",
    "            if isinstance(self._loss_scale, (int,float)) and self._loss_scale > 0:\n",
    "                loss_scale_mode = float(self._loss_scale)\n",
    "            else:\n",
    "                raise ValueError(\"Loss Scale is invalid, needs to be 'dynamic' or a positive int or float\")\n",
    "\n",
    "            # TODO: Add support later by going through the documentation for fixed scaling\n",
    "            self.optimizer = tf.keras.mixed_precision.LossScaleOptimizer(self._base_optimizer, initial_scale = loss_scale_mode)\n",
    "        \n",
    "        return self.optimizer\n",
    "\n",
    "    def scale_loss(self, gradients):\n",
    "        # Keeping this here for later if I decide to take control of the scaling and the clipping of the values\n",
    "        return gradients\n",
    "    \n",
    "    @contextmanager\n",
    "    def autocast(self):\n",
    "        yield\n",
    "\n",
    "    def state_metadata(self):\n",
    "        return {\n",
    "            'enabled': self._enabled,\n",
    "            'policy': self._policy,\n",
    "            'loss_scale': self._loss_scale,\n",
    "            'clip_unscaled_grads': self._clip_unscaled_grads,\n",
    "            'force_fp32': self._force_fp32\n",
    "        }\n",
    "\n",
    "    def make_precision_config(self):\n",
    "        return PrecisionConfig(self._force_fp32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d177fa1d-39ab-4b78-9633-db68ad2b80d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1766203543.242758    7367 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1766203543.329184    7367 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1766203543.329250    7367 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1766203543.330802    7367 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1766203543.330863    7367 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1766203543.330898    7367 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1766203543.526490    7367 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1766203543.526584    7367 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-19 23:05:43.526597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-12-19 23:05:43.526627: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:198] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1766203543.528221    7367 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-19 23:05:43.528261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74ee40de-c760-4bbc-8c70-0d499df82aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'enabled': True,\n",
    " 'policy': 'mixed_float16',\n",
    " 'loss_scale': 'dynamic',\n",
    " 'clip_unscaled_grads': True,\n",
    " 'force_fp32': ['loss_reduction', 'box_encode_decode', 'iou', 'nms']}\n",
    "amp = AMPContext(config, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0463b04-a028-43a5-94f9-e0e2f4588594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enabled': True,\n",
       " 'policy': 'mixed_float16',\n",
       " 'loss_scale': 'dynamic',\n",
       " 'clip_unscaled_grads': True,\n",
       " 'force_fp32': {'box_encode_decode', 'iou', 'loss_reduction', 'nms'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amp.state_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53adfcb0-2fe8-495f-be2f-5106b0ac4353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.optimizers.loss_scale_optimizer.LossScaleOptimizer at 0x77dc5cdbd8d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amp.wrap_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cd75743-0f9a-4286-8491-7a44b8568e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.optimizers.loss_scale_optimizer.LossScaleOptimizer object at 0x77dc5cdbd8d0>\n"
     ]
    }
   ],
   "source": [
    "with amp.autocast():\n",
    "    print(amp.optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d1d3cd-bb78-48e1-a3e1-24b1d1912681",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06978b73-8b4d-4e8f-9989-70f7fcf1ef35",
   "metadata": {},
   "source": [
    "### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "356ba490-69d0-4011-9c1f-a6fa9096e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.mixed_precision.set_global_policy(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c95d61fa-d6ee-4083-8059-b213bfb38904",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5054873e-8062-4a41-9b09-faebdbfd5487",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'enabled': True,\n",
    " 'policy': 'mixed_float16',\n",
    " 'loss_scale': 'dynamic',\n",
    " 'clip_unscaled_grads': True,\n",
    " 'force_fp32': ['loss_reduction', 'box_encode_decode', 'iou', 'nms']}\n",
    "amp = AMPContext(config, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32408839-2d56-48af-a2a7-94f5b334c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp.setup_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c988c6e-0d38-4870-ac5c-db2cff408d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_policy_name = tf.keras.mixed_precision.global_policy().name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "877beefb-8e95-4dca-9590-f2f798563c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert global_policy_name == \"mixed_float16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93933aa9-0ae9-4f29-a8c1-c9e855050e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'enabled': False,\n",
    " 'policy': 'mixed_float16',\n",
    " 'loss_scale': 'dynamic',\n",
    " 'clip_unscaled_grads': True,\n",
    " 'force_fp32': ['loss_reduction', 'box_encode_decode', 'iou', 'nms']}\n",
    "amp = AMPContext(config, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4154e5d-6139-4781-ae4c-a8981fe3a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp.setup_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c6c8752-f7ef-4011-8b71-d80d854e96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_policy_name = tf.keras.mixed_precision.global_policy().name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9910b299-6104-4ebb-a8f0-410f0c6170f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert global_policy_name == \"float32\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f2699-17ae-4890-9a59-f6b34735119d",
   "metadata": {},
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e9d4647-1531-4eb9-aad3-bf7c4952619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0d590dd-88b7-4cd7-b31c-09ac61ebac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'enabled': True,\n",
    " 'policy': 'mixed_float16',\n",
    " 'loss_scale': 'dynamic',\n",
    " 'clip_unscaled_grads': True,\n",
    " 'force_fp32': ['loss_reduction', 'box_encode_decode', 'iou', 'nms']}\n",
    "amp = AMPContext(config, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97ca58ac-4cde-42a9-bba2-7b23bf6bd4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp.setup_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5efc1eb9-b591-4687-9aa1-272da173b158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.optimizers.loss_scale_optimizer.LossScaleOptimizer at 0x77dc5cdbf6a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amp.wrap_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d0a52df-44d7-4cab-bea7-2e578a5558c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert amp.optimizer is not opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deac788-e0a4-4965-849f-f148231478ea",
   "metadata": {},
   "source": [
    "### Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1ff5b22-0fcb-45f8-b606-50c4b1fb42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1146986-323e-47f4-a9d2-f41208039d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'enabled': False,\n",
    " 'policy': 'mixed_float16',\n",
    " 'loss_scale': 'dynamic',\n",
    " 'clip_unscaled_grads': True,\n",
    " 'force_fp32': ['loss_reduction', 'box_encode_decode', 'iou', 'nms']}\n",
    "amp = AMPContext(config, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c07d4ede-23a2-41cb-9154-4d5a10500b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp.setup_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0958a691-8de4-4200-aaae-eccbfc694688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.optimizers.adam.Adam at 0x77dc5cdc8ee0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amp.wrap_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65d6a292-b61c-4713-95ea-651a13f9b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert amp.optimizer is opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb55784-d332-46af-bcaf-f595c17c61ce",
   "metadata": {},
   "source": [
    "### Test 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f560db99-a044-4384-ad2e-5f542a5af7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.mixed_precision.set_global_policy(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dd4794d-0ca9-41b0-aa60-d948a0486166",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27d77321-e20c-4772-bba3-c7c2b82abe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'enabled': True,\n",
    " 'policy': 'mixed_float16',\n",
    " 'loss_scale': 'dynamic',\n",
    " 'clip_unscaled_grads': True,\n",
    " 'force_fp32': ['loss_reduction', 'box_encode_decode', 'iou', 'nms']}\n",
    "amp = AMPContext(config, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41e27944-0bd1-4d5b-878c-e538dffbc42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp.setup_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0337282-7027-434f-985c-d75081100523",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(16,)),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "488cdb6c-40ab-4669-a5c0-f385520fc1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.keras.mixed_precision.global_policy().name == \"mixed_float16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b081db9e-9d6d-48b7-a546-912a38aaf0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(tf.config.list_physical_devices(\"GPU\")) > 0:\n",
    "    assert model.layers[0].dtype_policy.compute_dtype == \"float16\"\n",
    "else:\n",
    "    assert model.layers[0].dtype_policy is not None    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e87932-7094-4b5b-a926-da4c41a1f095",
   "metadata": {},
   "source": [
    "### Test 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36c42cc8-c891-486c-8661-26949e6ca89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.mixed_precision.set_global_policy(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9397c239-6945-4b2d-8ddc-c857d2fc60c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9839103d-4c28-4de3-88e1-36ee67639b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'enabled': True,\n",
    " 'policy': 'mixed_float16',\n",
    " 'loss_scale': 'dynamic',\n",
    " 'clip_unscaled_grads': True,\n",
    " 'force_fp32': ['loss_reduction', 'box_encode_decode', 'iou', 'nms']}\n",
    "amp = AMPContext(config, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e198e1c7-3471-4267-85b1-a779091c68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp.setup_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49cde65d-c081-4053-9158-4fa5c657adb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.optimizers.loss_scale_optimizer.LossScaleOptimizer at 0x77dc5cdca860>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amp.wrap_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe82ff30-cc9e-450d-9484-94b13b14e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(16,)),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04562183-41c3-4de7-973d-4c546f23e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([8, 16])\n",
    "y = tf.random.normal([8, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e80b0d8b-5c4c-497d-b3cc-3c1028dd81c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0_before = tf.identity(model.trainable_variables[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4abedbb0-ed9d-4174-b6d8-18d22b9961ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    with amp.autocast():\n",
    "        y_pred = model(x, training=True)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        y_true = tf.cast(y, tf.float32)\n",
    "        loss = tf.reduce_mean(tf.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b87ecccf-bdce-49fe-94c0-fa6b8ba23d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = tape.gradient(loss, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "999c0640-a663-460d-8f37-d004ff1a8aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_count = sum(g is None for g in grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94e156ec-42ca-40aa-bb14-c152b817306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert none_count == 0, f\"Found {none_count} None gradients.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b50dfe23-e309-4501-83b9-68253ea0a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = amp.scale_loss(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a6101d9-9229-4c81-856d-661a6aff9703",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_norm = tf.linalg.global_norm(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "201862e0-5038-4478-a630-b22de372a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.math.is_finite(global_norm), \"Gradient norm is NaN/Inf.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "900c55fc-35d9-4e56-99f2-a3a6dc7f7b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert float(global_norm.numpy()) > 0.0, \"Gradient norm is zero (unexpected for random data).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "642e29c5-001c-444e-b49d-6aef699fa5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasVariable shape=(), dtype=int64, path=loss_scale_optimizer_2/iteration>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amp.optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c01ef8b-7896-47fc-b4ec-e5e78d0160d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0_after = model.trainable_variables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b48bda7c-4688-4e4a-9781-66bfae0c0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = tf.reduce_sum(tf.abs(tf.cast(w0_after, tf.float32) - tf.cast(w0_before, tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a2435d9-8414-4316-af9e-f1a8528d090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert float(delta.numpy()) > 0.0, \"Weights did not change after apply_gradients().\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f457f0a4-0a63-4688-9c99-1336a5c32f95",
   "metadata": {},
   "source": [
    "### Test 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "08a06d98-d041-4104-8ecc-c2ae2ed3ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'enabled': True,\n",
    " 'policy': 'mixed_float16',\n",
    " 'loss_scale': 'dynamic',\n",
    " 'clip_unscaled_grads': True,\n",
    " 'force_fp32': ['loss_reduction', 'box_encode_decode', 'iou', 'nms']}\n",
    "amp = AMPContext(config, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d0b21a5-8d29-4521-8591-4649dd78c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp.setup_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b8f19a26-91fe-4e43-8fa6-56ca803bec0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.optimizers.loss_scale_optimizer.LossScaleOptimizer at 0x77dc57f4d900>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amp.wrap_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f62233bf-80b7-4bd2-87ef-385e9a974566",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_config = amp.make_precision_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b64ae299-1c42-4442-80de-ba3bd5ffb848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'box_encode_decode', 'iou', 'loss_reduction', 'nms'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_config._forced_precision_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f7dfd86-db1b-4277-aa13-4fc9769e5d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilenetv2ssd.models.ssd.ops.encode_ops_tf import encode_boxes_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a7018120-cfa4-4567-9b1d-de912331c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "priors_cxcywh = tf.constant([0.5, 0.5, 0.2, 0.2], dtype = tf.float32)\n",
    "gt_xyxy =  tf.constant([\n",
    "    [0.10, 0.10, 0.30, 0.30],  # GT 0  (class e.g. 3)\n",
    "    [0.55, 0.55, 0.85, 0.85],  # GT 1  (class e.g. 2)\n",
    "    [0.20, 0.50, 0.40, 0.80],  # GT 2  (class e.g. 5)\n",
    "    [0.00, 0.00, 0.00, 0.00],  # padded\n",
    "], dtype=tf.float32)\n",
    "variance = (0.1,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8711397f-5f9e-4616-b8b7-e03dc9294daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[-1.5000000e+01, -1.5000000e+01,  5.9604639e-07,  5.9604639e-07],\n",
       "       [ 1.0000002e+01,  1.0000002e+01,  2.0273256e+00,  2.0273256e+00],\n",
       "       [-9.9999990e+00,  7.4999986e+00,  0.0000000e+00,  2.0273256e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_boxes_core(gt_xyxy,priors_cxcywh,variance, precision_config = precision_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8ad98366-152c-44d2-b48d-86e7f32d4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(16,)),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d083ab2f-6b72-4e2c-a6fe-cc0e1f503a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([8, 16])\n",
    "y = tf.random.normal([8, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e9d2da4-21f7-4a96-8299-e3c8e20ad2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    with amp.autocast():\n",
    "        y_pred = model(x, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd1d4189-859e-454d-b804-d650661a2c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mixed_float16'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.mixed_precision.global_policy().name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5d5ccd02-680d-4ee7-9537-0f75d6e2b274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.src.optimizers.loss_scale_optimizer.LossScaleOptimizer"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(amp.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "437d811f-f7d6-418d-94fa-2e07505ef9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred dtype: <dtype: 'float16'>\n",
      "var dtype: float32\n"
     ]
    }
   ],
   "source": [
    "print(\"y_pred dtype:\", y_pred.dtype)\n",
    "print(\"var dtype:\", model.trainable_variables[0].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77814f1-b554-4c04-a3e3-6b1a50166ef9",
   "metadata": {},
   "source": [
    "## Factory Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2554a20b-b4ff-41ef-960d-6a4d450d6517",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(main_cfg_path,model_cfg_path,data_cfg_path,eval_cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d2f9fab7-e9fe-4636-9201-26b031ef0f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_amp_config(config: dict[str, Any]):\n",
    "    train_config = config['train']\n",
    "    amp_opts = train_config.get('amp',{})\n",
    "\n",
    "    amp_config = {\n",
    "        'enabled': amp_opts.get('enabled', False),\n",
    "        'policy' : amp_opts.get('policy', \"float32\"),\n",
    "        'loss_scale': amp_opts.get('loss_scale', 'dynamic'),\n",
    "        'clip_unscaled_grads' : amp_opts.get('clip_unscaled_grads', True),\n",
    "        'force_fp32': amp_opts.get('force_fp32', {}),\n",
    "    }\n",
    "\n",
    "    return amp_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "85a82f8b-ddcc-4250-88f2-a457054fb853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enabled': True,\n",
       " 'policy': 'mixed_float16',\n",
       " 'loss_scale': 'dynamic',\n",
       " 'clip_unscaled_grads': True,\n",
       " 'force_fp32': ['loss_reduction', 'box_encode_decode', 'iou', 'nms']}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_amp_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "40829127-7882-4e2d-9069-83de07c8793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_amp(config: dict[str, Any], optimizer: tf.keras.optimizers.Optimizer):\n",
    "    # Build the AMP config\n",
    "    amp_config = build_amp_config(config)\n",
    "\n",
    "    # Build the AMP\n",
    "    amp = AMPContext(amp_config, optimizer)\n",
    "\n",
    "    return amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bb0457bb-9862-47e8-a200-4a4c2a9ef92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp = build_amp(config, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e21e62-5e61-42b4-bb9e-820793415fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
