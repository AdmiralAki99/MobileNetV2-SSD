{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083dacdb-1f70-4163-9ec0-bd67913c0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02825d4e-245c-41b8-be76-65ebc8e8081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Any, Iterator\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from abc import ABC, abstractmethod\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecbf1c5a-bc2c-4863-8501-47c4471e043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilenetv2ssd.core.config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02eec859-1163-482d-b30e-22b1713cb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cfg_path = \"configs/train/default.yaml\"\n",
    "model_cfg_path = \"configs/model/mobilenetv2_ssd_voc.yaml\"\n",
    "data_cfg_path = \"configs/data/voc_224.yaml\"\n",
    "eval_cfg_path = \"configs/eval/default.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e59868-3ff0-4556-919c-693928d1f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(main_cfg_path,model_cfg_path,data_cfg_path,eval_cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "731c5a16-2c8f-4767-9f29-e5d461186f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DetectionSample:\n",
    "    image: np.ndarray  # Shape: [H, W, 3]\n",
    "    boxes: np.ndarray  # Shape: [N, 4]\n",
    "    labels: np.ndarray # Shape: [N]\n",
    "    image_id: str\n",
    "    path: str\n",
    "    orig_size: tuple[int,int] # (height, width)\n",
    "    \n",
    "    def validate(self):\n",
    "        if self.image.ndim != 3 or self.image.shape[2] != 3:\n",
    "            raise ValueError(f\"Image must be [H,W,3], got {self.image.shape}\")\n",
    "\n",
    "        if self.image.dtype != np.float32:\n",
    "            raise ValueError(f\"Image must be float32, got {self.image.dtype}\")\n",
    "\n",
    "        # Checking for the Boxes\n",
    "        if self.boxes.ndim != 2 or (len(self.boxes) > 0 and self.boxes.shape[1] != 4):\n",
    "            raise ValueError(f\"Boxes must be [N,4], got {self.boxes.shape}\")\n",
    "\n",
    "        if self.boxes.dtype != np.float32:\n",
    "            raise ValueError(f\"Boxes must be float32, got {self.boxes.dtype}\")\n",
    "\n",
    "        # Checking for the Labels\n",
    "        if self.labels.ndim != 1:\n",
    "            raise ValueError(f\"Labels must be [N], got {self.labels.shape}\")\n",
    "\n",
    "        if len(self.boxes) != len(self.labels):\n",
    "            raise ValueError(f\"Boxes ({len(self.boxes)}) and labels ({len(self.labels)}) count mismatch\")\n",
    "\n",
    "        if self.labels.dtype != np.int32:\n",
    "            raise ValueError(f\"Labels must be int32, got {self.labels.dtype}\")\n",
    "\n",
    "        if len(self.labels) > 0 and np.any(self.labels < 1):\n",
    "            raise ValueError(f\"Labels must be >= 1 (0 is background), got min={self.labels.min()}\")\n",
    "\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"image\": self.image,\n",
    "            \"boxes\": self.boxes,\n",
    "            \"labels\": self.labels,\n",
    "            \"image_id\": self.image_id,\n",
    "            \"path\": self.path,\n",
    "            \"orig_size\": np.array(self.orig_size, dtype=np.int32),\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25078399-ef04-4bbd-807a-12c74932ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDetectionDataset(ABC):\n",
    "    def __init__(self,root: str | Path, split: str, classes_file: str | Path, use_difficult: bool = False, validate: bool = True):\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.use_difficult = use_difficult\n",
    "        self._validate = validate\n",
    "\n",
    "        self._class_names = self._load_classes(classes_file)\n",
    "\n",
    "        self._class_to_index = {name: i + 1 for i, name in enumerate(self._class_names)}\n",
    "        self._index_to_class = {i + 1: name for i, name in enumerate(self._class_names)}\n",
    "        self._index_to_class[0] = \"background\"\n",
    "\n",
    "    def _load_classes(self,classes_file: str | Path):\n",
    "        classes_file = Path(classes_file)\n",
    "\n",
    "        # Checking if it exists\n",
    "        if not classes_file.exists():\n",
    "            raise FileNotFoundError(f\"Classes file not found: {classes_file}\")\n",
    "\n",
    "        with open(classes_file, \"r\") as f:\n",
    "            return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    def class_names(self):\n",
    "        return self._class_names\n",
    "\n",
    "    def class_to_index(self):\n",
    "        return self._class_to_index\n",
    "\n",
    "    def class_to_index(self):\n",
    "        return {name: i + 1 for i, name in enumerate(self.class_names)}\n",
    "\n",
    "    def index_to_class(self):\n",
    "        mapping = {i + 1: name for i, name in enumerate(self.class_names)}\n",
    "        mapping[0] = \"background\"\n",
    "        return mapping\n",
    "\n",
    "    def index_to_class(self):\n",
    "        return self._index_to_class\n",
    "\n",
    "    def num_classes(self):\n",
    "        return len(self._class_names) + 1\n",
    "\n",
    "    @abstractmethod\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def _load_sample(self, index: int):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _clean_boxes(self, sample: DetectionSample):\n",
    "\n",
    "        boxes = sample.boxes\n",
    "        labels = sample.labels\n",
    "        H,W = sample.image.shape[:2]\n",
    "\n",
    "        # Checking for the boxes\n",
    "        if len(boxes) == 0:\n",
    "            return sample\n",
    "\n",
    "        # Cleaning the boxes first\n",
    "        boxes = boxes.copy()\n",
    "        boxes[:, [0,2]] = np.clip(boxes[:, [0,2]], 0, W)\n",
    "        boxes[:, [1,3]] = np.clip(boxes[:, [1,3]], 0, H)\n",
    "\n",
    "        # Checking for the degenerate boxes\n",
    "        widths = boxes[:, 2] - boxes[:, 0]\n",
    "        heights = boxes[:, 3] - boxes[:, 1]\n",
    "        valid_mask = (widths > 0) & (heights > 0)\n",
    "\n",
    "        # Removing NaN Boxes\n",
    "        finite_mask = np.all(np.isfinite(boxes), axis = 1)\n",
    "        valid_mask = valid_mask & finite_mask\n",
    "\n",
    "        return DetectionSample(\n",
    "            image = sample.image,\n",
    "            boxes = boxes[valid_mask],\n",
    "            labels= labels[valid_mask],\n",
    "            image_id=sample.image_id,\n",
    "            path=sample.path,\n",
    "            orig_size=sample.orig_size,\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        if index < 0 or index >= len(self):\n",
    "            raise IndexError(f\"Index {index} out of range [0, {len(self)})\")\n",
    "\n",
    "        sample = self._load_sample(index)\n",
    "        sample = self._clean_boxes(sample)\n",
    "\n",
    "        if self._validate:\n",
    "            sample.validate()\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self)):\n",
    "            yield self[i]\n",
    "\n",
    "    def generator(self):\n",
    "\n",
    "        for index in range(len(self)):\n",
    "            sample = self[index]\n",
    "            yield sample.to_dict()\n",
    "\n",
    "    def get_stats(self):\n",
    "        total_boxes = 0\n",
    "        class_counts = {name: 0 for name in self.class_names}\n",
    "        \n",
    "        for sample in self:\n",
    "            total_boxes = total_boxes + len(sample.boxes)\n",
    "            for label in sample.labels:\n",
    "                class_name = class_name = self.index_to_class[label]\n",
    "                class_counts[class_name] = class_counts + 1\n",
    "\n",
    "        return {\n",
    "            \"num_samples\": len(self),\n",
    "            \"total_boxes\": total_boxes,\n",
    "            \"avg_boxes_per_image\": total_boxes / len(self) if len(self) > 0 else 0,\n",
    "            \"class_distribution\": class_counts,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ae6322b-e25a-4cc7-951e-c58cbfe4e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _standardize_target(image, target : dict, index):\n",
    "    # Checking for keys in the targets\n",
    "        validation_keys = ['boxes','labels']\n",
    "        result = all(key in target for key in validation_keys)\n",
    "\n",
    "        if not result:\n",
    "            raise KeyError(\"target must contain 'boxes' and 'labels'\")\n",
    "\n",
    "        # Checking if the coordinates are in the xyxy format\n",
    "        boxes = target['boxes']\n",
    "        labels = target['labels']\n",
    "\n",
    "        boxes = tf.convert_to_tensor(boxes)\n",
    "        labels = tf.convert_to_tensor(labels)\n",
    "\n",
    "        if boxes.shape.rank == 1:\n",
    "            n = tf.shape(boxes)[0]\n",
    "\n",
    "            boxes = tf.cond(tf.equal(n,0), lambda: tf.reshape(boxes, [0,4]), lambda: tf.reshape(boxes, [1,4]))\n",
    "\n",
    "        if labels.shape.rank == 0:\n",
    "            labels = tf.reshape(labels,[1])      \n",
    "\n",
    "        # Checking and enforcing dtypes\n",
    "        boxes = tf.cast(boxes,tf.float32)\n",
    "        labels = tf.cast(labels, tf.int32)\n",
    "\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "\n",
    "        # Making sure the metadata exists\n",
    "        if 'image_id' not in target:\n",
    "            target['image_id'] = tf.constant(f'{index}',dtype= tf.string)\n",
    "        else:\n",
    "            # Convert to tensor with the initial value\n",
    "            image_id_tensor = tf.convert_to_tensor(target['image_id'],dtype= tf.string)\n",
    "            target['image_id'] = tf.reshape(image_id_tensor,[])\n",
    "\n",
    "        if 'hash_signature' not in target:\n",
    "            target['hash_signature'] = tf.constant('',dtype= tf.string)\n",
    "        else:\n",
    "            hash_signature_tensor = tf.convert_to_tensor(target['hash_signature'],dtype= tf.string)\n",
    "            target['hash_signature'] = tf.reshape(hash_signature_tensor,[])\n",
    "\n",
    "        if 'orig_size' not in target:\n",
    "            target['orig_size'] = tf.shape(image)[0:2]\n",
    "        else:\n",
    "            orig_size_tensor = tf.convert_to_tensor(target['orig_size'], dtype= tf.int32)\n",
    "            target['orig_size'] = tf.reshape(orig_size_tensor,[2])\n",
    "\n",
    "        if 'path' not in target:\n",
    "            target['path'] = tf.constant(\"\", dtype= tf.string)\n",
    "        else:\n",
    "            path_tensor = tf.convert_to_tensor(target['path'], dtype= tf.string)\n",
    "            target['path'] = tf.reshape(path_tensor,[])\n",
    "\n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bfd7da5-df06-42c3-b8e4-0f3fc4dd1057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1769146741.415590   17931 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1769146741.752651   17931 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1769146741.752718   17931 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1769146741.755822   17931 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1769146741.755992   17931 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1769146741.756071   17931 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1769146741.953515   17931 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1769146741.953653   17931 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-23 00:39:01.953671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2026-01-23 00:39:01.953737: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:198] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1769146741.954567   17931 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-23 00:39:01.954678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "image = tf.zeros([480, 640, 3], dtype=tf.uint8)\n",
    "\n",
    "target = {\n",
    "    \"boxes\": tf.constant([\n",
    "        [ 50.0,  60.0, 200.0, 300.0],\n",
    "        [320.0, 100.0, 500.0, 400.0],\n",
    "    ], dtype=tf.float32),\n",
    "    \"labels\": tf.constant([7, 15], dtype=tf.int32),\n",
    "    \"image_id\": \"2007_000027\",\n",
    "    \"path\": \"/datasets/VOCdevkit/VOC2007/JPEGImages/2007_000027.jpg\",\n",
    "}\n",
    "idx = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c120a1-10b5-4c11-9317-2199381e876b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': <tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       " array([[ 50.,  60., 200., 300.],\n",
       "        [320., 100., 500., 400.]], dtype=float32)>,\n",
       " 'labels': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 7, 15], dtype=int32)>,\n",
       " 'image_id': <tf.Tensor: shape=(), dtype=string, numpy=b'2007_000027'>,\n",
       " 'path': <tf.Tensor: shape=(), dtype=string, numpy=b'/datasets/VOCdevkit/VOC2007/JPEGImages/2007_000027.jpg'>,\n",
       " 'hash_signature': <tf.Tensor: shape=(), dtype=string, numpy=b''>,\n",
       " 'orig_size': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([480, 640], dtype=int32)>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_standardize_target(image, target, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25117233-1ee0-4b01-855e-b82abc9117eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.zeros([375, 500, 3], dtype=tf.uint8)\n",
    "\n",
    "target = {\n",
    "    \"boxes\": [\n",
    "        [48, 240, 195, 371],   # ints are fine as input\n",
    "        [  8,  12, 352, 150],\n",
    "    ],\n",
    "    \"labels\": [1, 14],         # should become int32 tensor\n",
    "}\n",
    "idx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5decea3-bac3-45d6-b134-30dd2e9463c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': <tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       " array([[ 48., 240., 195., 371.],\n",
       "        [  8.,  12., 352., 150.]], dtype=float32)>,\n",
       " 'labels': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 1, 14], dtype=int32)>,\n",
       " 'image_id': <tf.Tensor: shape=(), dtype=string, numpy=b'3'>,\n",
       " 'hash_signature': <tf.Tensor: shape=(), dtype=string, numpy=b''>,\n",
       " 'orig_size': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([375, 500], dtype=int32)>,\n",
       " 'path': <tf.Tensor: shape=(), dtype=string, numpy=b''>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_standardize_target(image, target, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2ff006b-94e1-45f2-9661-d336004e783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.zeros([224, 224, 3], dtype=tf.uint8)\n",
    "\n",
    "target = {\n",
    "    \"boxes\": [20, 30, 100, 180],  # WRONG SHAPE INPUT (should be [[...]])\n",
    "    \"labels\": 5,                  # scalar label\n",
    "}\n",
    "idx = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96c1b072-19c3-48f3-961f-df1b438761cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[ 20.,  30., 100., 180.]], dtype=float32)>,\n",
       " 'labels': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([5], dtype=int32)>,\n",
       " 'image_id': <tf.Tensor: shape=(), dtype=string, numpy=b'99'>,\n",
       " 'hash_signature': <tf.Tensor: shape=(), dtype=string, numpy=b''>,\n",
       " 'orig_size': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([224, 224], dtype=int32)>,\n",
       " 'path': <tf.Tensor: shape=(), dtype=string, numpy=b''>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_standardize_target(image, target, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b0cc86d-613e-438a-93b3-5269742edf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sanitize_target(image, target):\n",
    "  # Check for degenerate boxes which are x2 <= x1 or y2 <= y1\n",
    "    boxes = target['boxes']\n",
    "    labels = target['labels']\n",
    "\n",
    "    finite_mask = tf.reduce_all(tf.math.is_finite(boxes), axis=-1)\n",
    "    boxes = tf.boolean_mask(boxes, finite_mask)\n",
    "    labels = tf.boolean_mask(labels, finite_mask)\n",
    "        \n",
    "    # Enforcing the shapes\n",
    "    boxes = tf.cast(boxes, tf.float32)\n",
    "    labels = tf.cast(labels, tf.int32)\n",
    "\n",
    "    boxes = tf.reshape(boxes, [-1,4])\n",
    "    labels = tf.reshape(labels, [-1])\n",
    "    \n",
    "    # Clip boxes to the original dimensions\n",
    "    H,W = target['orig_size']\n",
    "\n",
    "    H = tf.cast(H, tf.float32)\n",
    "    W = tf.cast(W, tf.float32)\n",
    "    \n",
    "    x1, y1, x2, y2 = tf.split(boxes,num_or_size_splits = 4, axis = -1)\n",
    "\n",
    "    x1 = tf.cast(x1, tf.float32)\n",
    "    y1 = tf.cast(y1, tf.float32)\n",
    "    x2 = tf.cast(x2, tf.float32)\n",
    "    y2 = tf.cast(y2, tf.float32)\n",
    "\n",
    "    x1 = tf.clip_by_value(x1, 0, W)\n",
    "    y1 = tf.clip_by_value(y1, 0, H)\n",
    "    x2 = tf.clip_by_value(x2, 0, W)\n",
    "    y2 = tf.clip_by_value(y2, 0, H)\n",
    "\n",
    "    boxes = tf.concat([x1, y1, x2, y2], axis = -1)\n",
    "\n",
    "    x1, y1, x2, y2 = tf.split(boxes, num_or_size_splits = 4, axis = -1)\n",
    "\n",
    "    degenerate_validity = tf.math.logical_or(x2 <= x1, y2 <= y1)\n",
    "    degenerate_validity = tf.reshape(tf.math.logical_not(degenerate_validity),[-1])\n",
    "\n",
    "    boxes = tf.boolean_mask(boxes,degenerate_validity)\n",
    "\n",
    "    # Filtering the labels too\n",
    "    labels = tf.boolean_mask(labels, degenerate_validity)\n",
    "\n",
    "    target['boxes'] = boxes\n",
    "    target['labels'] = labels\n",
    "\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3d59065-b4c6-4913-882e-e4d9f9774702",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.random.uniform(shape=(224, 224, 3), minval=0, maxval=255, dtype=tf.int32)\n",
    "image = tf.cast(image, tf.uint8)  # typical \"raw\" image dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29df17dd-b81b-4bc2-91e5-ad851ab41e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_clean = {\n",
    "    \"boxes\": tf.constant([\n",
    "        [10.0,  20.0,  60.0,  80.0],   # valid\n",
    "        [120.0, 40.0, 200.0, 210.0],   # valid\n",
    "    ], dtype=tf.float32),\n",
    "    \"labels\": tf.constant([3, 15], dtype=tf.int32),\n",
    "    \"image_id\": tf.constant(42),\n",
    "    \"path\": \"VOCdevkit/VOC2007/JPEGImages/000042.jpg\",\n",
    "    \"orig_size\": tf.constant([224, 224], dtype=tf.int32),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d0e6122-33d4-458a-8538-7a726576556d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': <tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       " array([[ 10.,  20.,  60.,  80.],\n",
       "        [120.,  40., 200., 210.]], dtype=float32)>,\n",
       " 'labels': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 3, 15], dtype=int32)>,\n",
       " 'image_id': <tf.Tensor: shape=(), dtype=int32, numpy=42>,\n",
       " 'path': 'VOCdevkit/VOC2007/JPEGImages/000042.jpg',\n",
       " 'orig_size': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([224, 224], dtype=int32)>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sanitize_target(image, target_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "162b2760-488c-400c-a968-47112d99c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_degenerate = {\n",
    "    \"boxes\": tf.constant([\n",
    "        [10.0,  20.0,  60.0,  80.0],   # valid\n",
    "        [50.0,  30.0,  40.0,  90.0],   # x2 < x1  -> invalid\n",
    "        [12.0, 100.0,  40.0,  90.0],   # y2 < y1  -> invalid\n",
    "        [70.0,  70.0,  70.0, 120.0],   # x2 == x1 -> zero width -> invalid\n",
    "    ], dtype=tf.float32),\n",
    "    \"labels\": tf.constant([1, 2, 3, 4], dtype=tf.int32),\n",
    "    \"image_id\": tf.constant(7),\n",
    "    \"orig_size\": tf.constant([224, 224], dtype=tf.int32),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0d0b85d-6fde-48b2-8518-eb3169262a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[10., 20., 60., 80.]], dtype=float32)>,\n",
       " 'labels': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>,\n",
       " 'image_id': <tf.Tensor: shape=(), dtype=int32, numpy=7>,\n",
       " 'orig_size': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([224, 224], dtype=int32)>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sanitize_target(image, target_degenerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eae8db6d-9170-4ac1-af33-4b320250cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_oob = {\n",
    "    \"boxes\": tf.constant([\n",
    "        [-10.0,  10.0,  50.0,  60.0],  # x1 < 0\n",
    "        [ 20.0, -15.0, 100.0,  40.0],  # y1 < 0\n",
    "        [150.0, 150.0, 300.0, 260.0],  # x2, y2 > bounds\n",
    "        [-20.0, -20.0, 500.0, 500.0],  # huge overflow\n",
    "    ], dtype=tf.float32),\n",
    "    \"labels\": tf.constant([5, 6, 7, 8], dtype=tf.int32),\n",
    "    \"image_id\": tf.constant(99),\n",
    "    \"orig_size\": tf.constant([224, 224], dtype=tf.int32),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8469b25c-c166-40d7-8e3e-bbfe5da50846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': <tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       " array([[  0.,  10.,  50.,  60.],\n",
       "        [ 20.,   0., 100.,  40.],\n",
       "        [150., 150., 224., 224.],\n",
       "        [  0.,   0., 224., 224.]], dtype=float32)>,\n",
       " 'labels': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([5, 6, 7, 8], dtype=int32)>,\n",
       " 'image_id': <tf.Tensor: shape=(), dtype=int32, numpy=99>,\n",
       " 'orig_size': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([224, 224], dtype=int32)>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sanitize_target(image, target_oob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e778ac95-79f7-4b56-9e26-3e728255df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_nan_inf = {\n",
    "    \"boxes\": tf.constant([\n",
    "        [10.0, 20.0, 60.0, 80.0],            # valid\n",
    "        [float(\"nan\"), 5.0, 20.0, 25.0],     # NaN\n",
    "        [10.0, float(\"inf\"), 20.0, 25.0],    # Inf\n",
    "    ], dtype=tf.float32),\n",
    "    \"labels\": tf.constant([1, 2, 3], dtype=tf.int32),\n",
    "    \"image_id\": tf.constant(555),\n",
    "    \"orig_size\": tf.constant([224, 224], dtype=tf.int32),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3951b24-7548-4f87-adf5-ed001c847978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[10., 20., 60., 80.]], dtype=float32)>,\n",
       " 'labels': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>,\n",
       " 'image_id': <tf.Tensor: shape=(), dtype=int32, numpy=555>,\n",
       " 'orig_size': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([224, 224], dtype=int32)>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sanitize_target(image, target_nan_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be2c5d03-0100-4fca-8468-f8408b72e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_target(image, target):\n",
    "    boxes = target['boxes']\n",
    "    labels = target['labels']\n",
    "\n",
    "    # Checking for Target boxes\n",
    "    tf.debugging.assert_equal(tf.rank(boxes), 2, \"boxes must be rank-2: [N,4]\")\n",
    "    tf.debugging.assert_equal(tf.shape(boxes)[-1], 4, \"boxes last dim must be 4\")\n",
    "    tf.debugging.assert_equal(tf.rank(labels), 1, \"labels must be rank-1: [N]\")\n",
    "    tf.debugging.assert_equal(tf.shape(boxes)[0], tf.shape(labels)[0], \"boxes and labels must have same N\")\n",
    "        \n",
    "\n",
    "    tf.debugging.assert_equal(tf.reduce_all(tf.math.is_finite(boxes)), True, \"boxes contain NaN/Inf\")\n",
    "\n",
    "    x1, y1, x2, y2 = tf.split(boxes,num_or_size_splits = 4, axis = -1)\n",
    "\n",
    "    x1 = tf.cast(x1, tf.float32)\n",
    "    y1 = tf.cast(y1, tf.float32)\n",
    "    x2 = tf.cast(x2, tf.float32)\n",
    "    y2 = tf.cast(y2, tf.float32)\n",
    "\n",
    "    tf.debugging.assert_less_equal(x1, x2, message= \" x1 <= x2 condition violated\")\n",
    "    tf.debugging.assert_less_equal(y1, y2, message= \" y1 <= y2 condition violated\")\n",
    "\n",
    "    # Checking if the coordinates are in the bounds of the image\n",
    "    image_shape = tf.shape(image)\n",
    "    \n",
    "    H = tf.cast(image_shape[0], tf.float32)\n",
    "    W = tf.cast(image_shape[1], tf.float32)\n",
    "    \n",
    "    # Checking if the coordinates are within bounds\n",
    "    x1_condition = tf.math.logical_and((x1 >= 0),(x1 <= W))\n",
    "    x2_condition = tf.math.logical_and((x2 >= 0),(x2 <= W))\n",
    "    \n",
    "    x_validity = tf.reduce_all(tf.math.logical_and(x1_condition, x2_condition ))\n",
    "\n",
    "    y1_condition = tf.math.logical_and((y1 >= 0),(y1 <= H))\n",
    "    y2_condition = tf.math.logical_and((y2 >= 0),(y2 <= H))\n",
    "    \n",
    "    y_validity = tf.reduce_all(tf.math.logical_and(y1_condition, y2_condition))\n",
    "    \n",
    "    tf.debugging.assert_equal(x_validity, tf.constant(True, tf.bool), message = \"Failed to validate x conditions\")\n",
    "    tf.debugging.assert_equal(y_validity, tf.constant(True, tf.bool), message = \"Failed to validate y conditions\")\n",
    "\n",
    "    tf.debugging.assert_type(labels, tf.int32)\n",
    "    tf.debugging.assert_greater_equal(tf.reduce_min(labels), 1, \"labels must be >= 1 (0 is background)\")\n",
    "\n",
    "    # Checking for the other targets attributes\n",
    "    tf.debugging.assert_equal(tf.rank(target[\"image_id\"]), 0, f\"image_id must be scalar, {target['image_id']}, got rank: {tf.rank(target['image_id'])}\")\n",
    "    tf.debugging.assert_equal(tf.rank(target[\"orig_size\"]), 1, \"orig_size must be rank-1\")\n",
    "    tf.debugging.assert_equal(tf.shape(target[\"orig_size\"])[0], 2, \"orig_size must be [2] (H,W)\")\n",
    "    # tf.debugging.assert_less_equal(tf.reduce_max(labels),self._num_classes - 1,\"label id out of range\")\n",
    "\n",
    "    # Checking the intensity values of an image\n",
    "    tf.debugging.assert_equal(tf.rank(image), 3, \"image must be [H,W,3]\")\n",
    "    tf.debugging.assert_equal(tf.shape(image)[-1], 3, \"image must have 3 channels\")\n",
    "\n",
    "    tf.debugging.assert_equal(tf.rank(image),tf.constant(3, dtype = tf.int32), message = \"The rank is not the same for the images\")\n",
    "    tf.debugging.assert_equal(tf.shape(image)[-1],tf.constant(3, dtype = tf.int32), message = \"The channel dimension is invalid for image\")\n",
    "    tf.debugging.assert_equal(tf.math.reduce_all(tf.math.is_finite(tf.cast(image, dtype=tf.float32))), tf.constant(True, dtype= tf.bool), message = \"The image intensities are not finite\")\n",
    "            \n",
    "    # tf.debugging.assert_equal(target['path'].dtype, tf.string, \"path is invalid for targets\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1dda567-b1a0-4070-8d14-275cc456de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_validate_target(image,target_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64285dde-5c3e-4fec-b9ff-06f75a8afab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
